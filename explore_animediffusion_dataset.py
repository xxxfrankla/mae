#!/usr/bin/env python3
"""
æ¢ç´¢ AnimeDiffusion æ•°æ®é›†
äº†è§£æ–°æ•°æ®é›†çš„ç»“æ„å’Œå†…å®¹
"""

import os
from datasets import load_dataset
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

def explore_animediffusion_dataset():
    """æ¢ç´¢ AnimeDiffusion æ•°æ®é›†"""
    print("ğŸŒ åŠ è½½ AnimeDiffusion æ•°æ®é›†...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        ds = load_dataset("Mercity/AnimeDiffusion_Dataset")
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"  - æ•°æ®é›†ç»“æ„: {ds}")
        
        # æ£€æŸ¥å„ä¸ªåˆ†å‰²
        for split_name, split_data in ds.items():
            print(f"  - {split_name}: {len(split_data)} æ ·æœ¬")
            
            # æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬
            if len(split_data) > 0:
                sample = split_data[0]
                print(f"    æ ·æœ¬ç»“æ„: {sample.keys()}")
                
                # å¦‚æœæœ‰å›¾åƒï¼Œæ˜¾ç¤ºå›¾åƒä¿¡æ¯
                if 'image' in sample:
                    img = sample['image']
                    if isinstance(img, Image.Image):
                        print(f"    å›¾åƒå°ºå¯¸: {img.size}")
                        print(f"    å›¾åƒæ¨¡å¼: {img.mode}")
                
                # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„æ–‡æœ¬å­—æ®µ
                text_fields = ['caption', 'text', 'prompt', 'description']
                for field in text_fields:
                    if field in sample:
                        text_content = sample[field]
                        print(f"    {field}ç¤ºä¾‹: {str(text_content)[:100]}...")
                        break
        
        return ds
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return None

def visualize_animediffusion_samples(ds, num_samples=6):
    """å¯è§†åŒ– AnimeDiffusion æ•°æ®é›†æ ·æœ¬"""
    print(f"\nğŸ¨ å¯è§†åŒ– {num_samples} ä¸ª AnimeDiffusion æ ·æœ¬...")
    
    # ä½¿ç”¨è®­ç»ƒé›†æˆ–ç¬¬ä¸€ä¸ªå¯ç”¨çš„åˆ†å‰²
    if 'train' in ds:
        split_data = ds['train']
        split_name = 'train'
    else:
        split_name = list(ds.keys())[0]
        split_data = ds[split_name]
        print(f"ä½¿ç”¨ {split_name} åˆ†å‰²")
    
    if len(split_data) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©º")
        return
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    sample_indices = np.random.choice(len(split_data), min(num_samples, len(split_data)), replace=False)
    
    for i, idx in enumerate(sample_indices):
        try:
            sample = split_data[int(idx)]
            
            if 'image' in sample:
                img = sample['image']
                if isinstance(img, Image.Image):
                    axes[i].imshow(img)
                    
                    # æ·»åŠ æ ‡é¢˜
                    title = f"Sample {i+1}"
                    
                    # æŸ¥æ‰¾æ–‡æœ¬æè¿°
                    text_fields = ['caption', 'text', 'prompt', 'description']
                    for field in text_fields:
                        if field in sample and sample[field]:
                            text_content = str(sample[field])
                            if len(text_content) > 50:
                                text_content = text_content[:47] + "..."
                            title += f"\n{text_content}"
                            break
                    
                    axes[i].set_title(title, fontsize=10)
                    axes[i].axis('off')
                else:
                    axes[i].text(0.5, 0.5, f'Sample {i+1}\nNo Image', 
                               ha='center', va='center')
                    axes[i].axis('off')
            else:
                axes[i].text(0.5, 0.5, f'Sample {i+1}\nNo Image Field', 
                           ha='center', va='center')
                axes[i].axis('off')
                
        except Exception as e:
            print(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
            axes[i].text(0.5, 0.5, f'Sample {i+1}\nError: {str(e)[:30]}', 
                       ha='center', va='center')
            axes[i].axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(num_samples, len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.savefig('animediffusion_dataset_samples.png', dpi=150, bbox_inches='tight')
    print("âœ… æ ·æœ¬å¯è§†åŒ–ä¿å­˜: animediffusion_dataset_samples.png")
    plt.show()

def analyze_animediffusion_stats(ds):
    """åˆ†æ AnimeDiffusion æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nğŸ“ˆ AnimeDiffusion æ•°æ®é›†ç»Ÿè®¡åˆ†æ...")
    
    # ä½¿ç”¨è®­ç»ƒé›†æˆ–ç¬¬ä¸€ä¸ªå¯ç”¨çš„åˆ†å‰²
    if 'train' in ds:
        split_data = ds['train']
        split_name = 'train'
    else:
        split_name = list(ds.keys())[0]
        split_data = ds[split_name]
    
    print(f"åˆ†æ {split_name} åˆ†å‰²...")
    
    # åˆ†æå›¾åƒå°ºå¯¸
    image_sizes = []
    image_modes = []
    text_lengths = []
    
    sample_size = min(1000, len(split_data))  # åˆ†æå‰1000ä¸ªæ ·æœ¬
    print(f"åˆ†æå‰ {sample_size} ä¸ªæ ·æœ¬...")
    
    for i in range(sample_size):
        try:
            sample = split_data[i]
            
            if 'image' in sample:
                img = sample['image']
                if isinstance(img, Image.Image):
                    image_sizes.append(img.size)
                    image_modes.append(img.mode)
            
            # æŸ¥æ‰¾æ–‡æœ¬å­—æ®µ
            text_fields = ['caption', 'text', 'prompt', 'description']
            for field in text_fields:
                if field in sample and sample[field]:
                    text_lengths.append(len(str(sample[field])))
                    break
                
        except Exception as e:
            continue
    
    # ç»Ÿè®¡ç»“æœ
    if image_sizes:
        widths = [size[0] for size in image_sizes]
        heights = [size[1] for size in image_sizes]
        
        print(f"\nğŸ–¼ï¸  å›¾åƒç»Ÿè®¡:")
        print(f"  æ ·æœ¬æ•°é‡: {len(image_sizes)}")
        print(f"  å®½åº¦èŒƒå›´: {min(widths)} - {max(widths)}")
        print(f"  é«˜åº¦èŒƒå›´: {min(heights)} - {max(heights)}")
        print(f"  å¹³å‡å°ºå¯¸: {np.mean(widths):.1f} x {np.mean(heights):.1f}")
        
        # ç»Ÿè®¡å¸¸è§å°ºå¯¸
        size_counts = {}
        for size in image_sizes:
            size_counts[size] = size_counts.get(size, 0) + 1
        
        print(f"  æœ€å¸¸è§çš„5ä¸ªå°ºå¯¸:")
        for size, count in sorted(size_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"    {size[0]}x{size[1]}: {count} å¼  ({count/len(image_sizes)*100:.1f}%)")
    
    if image_modes:
        mode_counts = {}
        for mode in image_modes:
            mode_counts[mode] = mode_counts.get(mode, 0) + 1
        
        print(f"\nğŸ¨ å›¾åƒæ¨¡å¼:")
        for mode, count in mode_counts.items():
            print(f"  {mode}: {count} å¼  ({count/len(image_modes)*100:.1f}%)")
    
    if text_lengths:
        print(f"\nğŸ“ æ–‡æœ¬ç»Ÿè®¡:")
        print(f"  å¹³å‡é•¿åº¦: {np.mean(text_lengths):.1f} å­—ç¬¦")
        print(f"  é•¿åº¦èŒƒå›´: {min(text_lengths)} - {max(text_lengths)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ AnimeDiffusion æ•°æ®é›†æ¢ç´¢å·¥å…·")
    print("=" * 50)
    
    # 1. æ¢ç´¢æ•°æ®é›†
    ds = explore_animediffusion_dataset()
    
    if ds is None:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®é›†ï¼Œé€€å‡º")
        return
    
    # 2. å¯è§†åŒ–æ ·æœ¬
    try:
        visualize_animediffusion_samples(ds)
    except Exception as e:
        print(f"å¯è§†åŒ–å¤±è´¥: {e}")
    
    # 3. åˆ†æç»Ÿè®¡ä¿¡æ¯
    try:
        analyze_animediffusion_stats(ds)
    except Exception as e:
        print(f"ç»Ÿè®¡åˆ†æå¤±è´¥: {e}")
    
    print(f"\nğŸ‰ AnimeDiffusion æ•°æ®é›†æ¢ç´¢å®Œæˆ!")
    print(f"ğŸ’¡ ä¸‹ä¸€æ­¥å¯ä»¥:")
    print(f"  1. åˆ›å»ºé€‚é…çš„æ•°æ®åŠ è½½å™¨")
    print(f"  2. åœ¨ AnimeDiffusion æ•°æ®é›†ä¸Šè¿è¡ŒMAEé¢„è®­ç»ƒ")
    print(f"  3. å¯¹æ¯”ä¸åŒåŠ¨æ¼«æ•°æ®é›†çš„è®­ç»ƒæ•ˆæœ")

if __name__ == "__main__":
    main()


