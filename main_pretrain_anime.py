#!/usr/bin/env python3
"""
åœ¨åŠ¨æ¼«æ•°æ®é›†ä¸Šè¿›è¡Œ MAE é¢„è®­ç»ƒ
ä¸“ä¸º Apple M4 å’ŒåŠ¨æ¼«æ•°æ®ä¼˜åŒ–
"""

import argparse
import datetime
import json
import numpy as np
import os
import time
from pathlib import Path

import torch
import torch.backends.cudnn as cudnn
from torch.utils.tensorboard import SummaryWriter

import timm
assert timm.__version__ == "0.3.2"
import timm.optim.optim_factory as optim_factory

import util.misc as misc
from util.misc_mps import NativeScalerWithGradNormCount as NativeScaler

import models_mae
from engine_pretrain_mps import train_one_epoch
from anime_dataset_loader import create_anime_dataloader

def get_args_parser():
    parser = argparse.ArgumentParser('MAE pre-training on Anime Dataset', add_help=False)
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', default=8, type=int,
                        help='Batch size per GPU')
    parser.add_argument('--accum_iter', default=16, type=int,
                        help='Accumulate gradient iterations')
    parser.add_argument('--epochs', default=50, type=int)
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model', default='mae_vit_base_patch16', type=str,
                        help='Name of model to train')
    parser.add_argument('--input_size', default=224, type=int,
                        help='images input size')
    parser.add_argument('--mask_ratio', default=0.75, type=float,
                        help='Masking ratio (percentage of removed patches).')
    parser.add_argument('--norm_pix_loss', action='store_true',
                        help='Use (per-patch) normalized pixels as targets')
    parser.set_defaults(norm_pix_loss=True)  # é»˜è®¤ä½¿ç”¨å½’ä¸€åŒ–åƒç´ æŸå¤±
    
    # ä¼˜åŒ–å™¨å‚æ•°
    parser.add_argument('--weight_decay', type=float, default=0.05,
                        help='weight decay (default: 0.05)')
    parser.add_argument('--lr', type=float, default=None, metavar='LR',
                        help='learning rate (absolute lr)')
    parser.add_argument('--blr', type=float, default=1.5e-4, metavar='LR',
                        help='base learning rate')
    parser.add_argument('--min_lr', type=float, default=0., metavar='LR',
                        help='lower lr bound for cyclic schedulers')
    parser.add_argument('--warmup_epochs', type=int, default=10, metavar='N',
                        help='epochs to warmup LR')
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument('--max_samples', type=int, default=None,
                        help='Maximum number of samples to use (for testing)')
    parser.add_argument('--output_dir', default='./output_anime',
                        help='path where to save')
    parser.add_argument('--log_dir', default='./output_anime',
                        help='path where to tensorboard log')
    parser.add_argument('--device', default='mps',
                        help='device to use for training')
    parser.add_argument('--seed', default=0, type=int)
    parser.add_argument('--resume', default='',
                        help='resume from checkpoint')
    parser.add_argument('--start_epoch', default=0, type=int,
                        help='start epoch')
    parser.add_argument('--num_workers', default=4, type=int)
    
    # ä¿å­˜å‚æ•°
    parser.add_argument('--save_freq', default=10, type=int,
                        help='Save checkpoint every N epochs')
    
    return parser

def main(args):
    print('ğŸŒ MAE åŠ¨æ¼«æ•°æ®é›†é¢„è®­ç»ƒå¼€å§‹')
    print('=' * 60)
    print("{}".format(args).replace(', ', ',\n'))

    device = torch.device(args.device)
    print(f'ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}')

    # è®¾ç½®éšæœºç§å­
    seed = args.seed
    torch.manual_seed(seed)
    np.random.seed(seed)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    Path(args.log_dir).mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºåŠ¨æ¼«æ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“¥ åˆ›å»ºåŠ¨æ¼«æ•°æ®åŠ è½½å™¨...")
    data_loader_train, dataset_train = create_anime_dataloader(
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        max_samples=args.max_samples,
        input_size=args.input_size
    )
    
    if data_loader_train is None:
        print("âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥")
        return
    
    print(f'ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:')
    print(f'  æ€»æ ·æœ¬æ•°: {len(dataset_train)}')
    print(f'  æ‰¹æ¬¡æ•°: {len(data_loader_train)}')
    print(f'  æ¯æ‰¹æ¬¡æ ·æœ¬: {args.batch_size}')
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ¤– åˆ›å»º {args.model} æ¨¡å‹...")
    model = models_mae.__dict__[args.model](norm_pix_loss=args.norm_pix_loss)
    model.to(device)
    
    model_without_ddp = model
    print("Model = %s" % str(model_without_ddp))
    
    # è®¡ç®—æœ‰æ•ˆæ‰¹æ¬¡å¤§å°å’Œå­¦ä¹ ç‡
    eff_batch_size = args.batch_size * args.accum_iter
    
    if args.lr is None:
        args.lr = args.blr * eff_batch_size / 256

    print(f"\nğŸ“ˆ è®­ç»ƒå‚æ•°:")
    print(f"  åŸºç¡€å­¦ä¹ ç‡: {args.blr:.2e}")
    print(f"  å®é™…å­¦ä¹ ç‡: {args.lr:.2e}")
    print(f"  æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {args.accum_iter}")
    print(f"  æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {eff_batch_size}")
    print(f"  æ©ç æ¯”ä¾‹: {args.mask_ratio}")

    # åˆ›å»ºä¼˜åŒ–å™¨
    param_groups = optim_factory.add_weight_decay(model_without_ddp, args.weight_decay)
    optimizer = torch.optim.AdamW(param_groups, lr=args.lr, betas=(0.9, 0.95))
    print(f"\nğŸ”§ ä¼˜åŒ–å™¨: {optimizer}")
    
    # åˆ›å»ºæŸå¤±ç¼©æ”¾å™¨
    loss_scaler = NativeScaler(device_type=device.type)

    # åŠ è½½æ£€æŸ¥ç‚¹
    misc.load_model(args=args, model_without_ddp=model_without_ddp, 
                   optimizer=optimizer, loss_scaler=loss_scaler)

    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    if args.log_dir is not None:
        log_writer = SummaryWriter(log_dir=args.log_dir)
    else:
        log_writer = None

    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {args.epochs} ä¸ªepoch...")
    start_time = time.time()
    
    best_loss = float('inf')
    
    for epoch in range(args.start_epoch, args.epochs):
        print(f"\nğŸ“… Epoch {epoch+1}/{args.epochs}")
        
        # è®­ç»ƒä¸€ä¸ªepoch
        train_stats = train_one_epoch(
            model, data_loader_train,
            optimizer, device, epoch, loss_scaler,
            log_writer=log_writer,
            args=args
        )
        
        # è®°å½•æœ€ä½³æŸå¤±
        current_loss = train_stats['loss']
        if current_loss < best_loss:
            best_loss = current_loss
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æŸå¤±: {best_loss:.4f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if args.output_dir and (epoch % args.save_freq == 0 or epoch + 1 == args.epochs):
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: epoch {epoch}")
            misc.save_model(
                args=args, model=model, model_without_ddp=model_without_ddp, 
                optimizer=optimizer, loss_scaler=loss_scaler, epoch=epoch)

        # è®°å½•æ—¥å¿—
        log_stats = {
            **{f'train_{k}': v for k, v in train_stats.items()},
            'epoch': epoch,
            'best_loss': best_loss
        }

        if args.output_dir and misc.is_main_process():
            if log_writer is not None:
                log_writer.flush()
            with open(os.path.join(args.output_dir, "log.txt"), mode="a", encoding="utf-8") as f:
                f.write(json.dumps(log_stats) + "\n")
        
        # æ˜¾ç¤ºè¿›åº¦
        elapsed_time = time.time() - start_time
        remaining_epochs = args.epochs - epoch - 1
        if epoch > 0:
            eta = elapsed_time / (epoch + 1 - args.start_epoch) * remaining_epochs
            eta_str = str(datetime.timedelta(seconds=int(eta)))
            print(f"â±ï¸  é¢„è®¡å‰©ä½™æ—¶é—´: {eta_str}")

    total_time = time.time() - start_time
    total_time_str = str(datetime.timedelta(seconds=int(total_time)))
    
    print(f'\nğŸ‰ è®­ç»ƒå®Œæˆ!')
    print(f'â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {total_time_str}')
    print(f'ğŸ† æœ€ä½³æŸå¤±: {best_loss:.4f}')
    print(f'ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {args.output_dir}')
    
    # ç”Ÿæˆè®­ç»ƒæ€»ç»“
    summary = {
        'dataset': 'anime-captions',
        'total_samples': len(dataset_train) if 'dataset_train' in locals() else 'unknown',
        'model': args.model,
        'epochs': args.epochs,
        'batch_size': args.batch_size,
        'effective_batch_size': eff_batch_size,
        'learning_rate': args.lr,
        'mask_ratio': args.mask_ratio,
        'best_loss': best_loss,
        'training_time': total_time_str,
        'device': str(device)
    }
    
    summary_path = os.path.join(args.output_dir, 'training_summary.json')
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"ğŸ“‹ è®­ç»ƒæ€»ç»“ä¿å­˜: {summary_path}")

if __name__ == '__main__':
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
    
    args = get_args_parser()
    args = args.parse_args()
    
    if args.output_dir:
        Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    
    main(args)
