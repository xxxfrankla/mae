#!/usr/bin/env python3
"""
æœ‰ç»„ç»‡çš„ MAE å¯è§†åŒ–å·¥å…·
æ¯æ¬¡è¿è¡Œéƒ½åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹ä¿å­˜ç»“æœ
"""

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import json
from datetime import datetime
from pathlib import Path

# è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import models_mae

class MAEVisualizer:
    def __init__(self, base_output_dir='./visualization_results'):
        """åˆå§‹åŒ–å¯è§†åŒ–å™¨"""
        self.base_output_dir = Path(base_output_dir)
        self.base_output_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å¤¹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = self.base_output_dir / f"mae_results_{timestamp}"
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {self.output_dir}")
        
        # åˆ›å»ºå­æ–‡ä»¶å¤¹
        self.curves_dir = self.output_dir / "training_curves"
        self.reconstruction_dir = self.output_dir / "reconstructions"
        self.analysis_dir = self.output_dir / "analysis"
        self.samples_dir = self.output_dir / "dataset_samples"
        
        for dir_path in [self.curves_dir, self.reconstruction_dir, self.analysis_dir, self.samples_dir]:
            dir_path.mkdir(exist_ok=True)
        
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

    def analyze_training_log(self, log_file='./output_m4/log.txt'):
        """åˆ†æè®­ç»ƒæ—¥å¿—å¹¶ç”Ÿæˆæ›²çº¿"""
        print("ğŸ“Š åˆ†æè®­ç»ƒæ—¥å¿—...")
        
        if not os.path.exists(log_file):
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            return None
        
        epochs = []
        losses = []
        lrs = []
        
        with open(log_file, 'r') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    epochs.append(data['epoch'])
                    losses.append(data['train_loss'])
                    lrs.append(data.get('train_lr', 0))
                except:
                    continue
        
        if not epochs:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
            return None
        
        # ç”Ÿæˆè®­ç»ƒæ›²çº¿
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
        
        # æŸå¤±æ›²çº¿
        ax1.plot(epochs, losses, 'b-', linewidth=2, marker='o', markersize=4)
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('MAE Training Loss Curve')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(bottom=0)
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i, (epoch, loss) in enumerate(zip(epochs, losses)):
            if i % max(1, len(epochs)//5) == 0:  # æ¯5ä¸ªç‚¹æ ‡æ³¨ä¸€æ¬¡
                ax1.annotate(f'{loss:.3f}', (epoch, loss), 
                           textcoords="offset points", xytext=(0,10), ha='center')
        
        # å­¦ä¹ ç‡æ›²çº¿
        ax2.plot(epochs, lrs, 'r-', linewidth=2, marker='s', markersize=4)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.set_title('Learning Rate Schedule')
        ax2.grid(True, alpha=0.3)
        ax2.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        curve_path = self.curves_dir / 'training_curves.png'
        plt.savefig(curve_path, dpi=150, bbox_inches='tight')
        print(f"âœ… è®­ç»ƒæ›²çº¿ä¿å­˜: {curve_path}")
        plt.close()
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_epochs': len(epochs),
            'initial_loss': losses[0],
            'final_loss': losses[-1],
            'loss_reduction': ((losses[0] - losses[-1]) / losses[0] * 100),
            'max_lr': max(lrs),
            'min_lr': min(lrs)
        }
        
        stats_path = self.analysis_dir / 'training_stats.json'
        with open(stats_path, 'w') as f:
            json.dump(stats, f, indent=2)
        
        print(f"ğŸ“ˆ è®­ç»ƒç»Ÿè®¡:")
        print(f"  è®­ç»ƒè½®æ•°: {stats['total_epochs']}")
        print(f"  åˆå§‹æŸå¤±: {stats['initial_loss']:.4f}")
        print(f"  æœ€ç»ˆæŸå¤±: {stats['final_loss']:.4f}")
        print(f"  æŸå¤±ä¸‹é™: {stats['loss_reduction']:.1f}%")
        print(f"  æœ€é«˜å­¦ä¹ ç‡: {stats['max_lr']:.2e}")
        
        return stats

    def show_dataset_samples(self, test_dir='./test_dataset/train'):
        """å±•ç¤ºæ•°æ®é›†æ ·æœ¬"""
        print("ğŸ–¼ï¸  å±•ç¤ºæµ‹è¯•æ•°æ®é›†æ ·æœ¬...")
        
        if not os.path.exists(test_dir):
            print(f"âŒ æµ‹è¯•æ•°æ®é›†ä¸å­˜åœ¨: {test_dir}")
            return
        
        # æ”¶é›†æ ·æœ¬
        class_samples = []
        class_names = sorted(os.listdir(test_dir))
        
        for class_name in class_names:
            class_path = os.path.join(test_dir, class_name)
            if os.path.isdir(class_path):
                img_files = sorted(os.listdir(class_path))
                if img_files:
                    # æ¯ä¸ªç±»åˆ«å–å‰3å¼ å›¾ç‰‡
                    for i, img_file in enumerate(img_files[:3]):
                        img_path = os.path.join(class_path, img_file)
                        class_samples.append((class_name, img_path, i))
        
        if not class_samples:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            return
        
        # æŒ‰ç±»åˆ«ç»„ç»‡æ ·æœ¬
        classes = {}
        for class_name, img_path, idx in class_samples:
            if class_name not in classes:
                classes[class_name] = []
            classes[class_name].append(img_path)
        
        # åˆ›å»ºç½‘æ ¼å¯è§†åŒ–
        n_classes = len(classes)
        max_samples = max(len(samples) for samples in classes.values())
        
        fig, axes = plt.subplots(n_classes, max_samples, figsize=(max_samples*3, n_classes*3))
        
        if n_classes == 1:
            axes = axes.reshape(1, -1)
        elif max_samples == 1:
            axes = axes.reshape(-1, 1)
        
        for i, (class_name, img_paths) in enumerate(classes.items()):
            for j, img_path in enumerate(img_paths):
                try:
                    img = Image.open(img_path).convert('RGB')
                    axes[i, j].imshow(img)
                    axes[i, j].set_title(f'{class_name} - {j+1}')
                    axes[i, j].axis('off')
                except Exception as e:
                    print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
            
            # å¡«å……ç©ºç™½ä½ç½®
            for j in range(len(img_paths), max_samples):
                axes[i, j].axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜ç»“æœ
        samples_path = self.samples_dir / 'dataset_samples_grid.png'
        plt.savefig(samples_path, dpi=150, bbox_inches='tight')
        print(f"âœ… æ•°æ®é›†æ ·æœ¬ä¿å­˜: {samples_path}")
        plt.close()
        
        # å•ç‹¬ä¿å­˜æ¯ä¸ªç±»åˆ«çš„ç¬¬ä¸€å¼ å›¾ç‰‡
        for class_name, img_paths in classes.items():
            if img_paths:
                try:
                    img = Image.open(img_paths[0]).convert('RGB')
                    class_path = self.samples_dir / f'{class_name}_sample.png'
                    img.save(class_path)
                except:
                    pass

    def visualize_mae_reconstruction(self, test_img_path=None):
        """å¯è§†åŒ– MAE é‡å»ºè¿‡ç¨‹"""
        print("ğŸ¨ ç”Ÿæˆ MAE é‡å»ºå¯è§†åŒ–...")
        
        # åˆ›å»ºæ¨¡å‹
        model = models_mae.mae_vit_base_patch16(norm_pix_loss=True)
        model.to(self.device)
        model.eval()
        
        # å›¾åƒé¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        inv_normalize = transforms.Normalize(
            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
            std=[1/0.229, 1/0.224, 1/0.225]
        )
        
        # æ‰¾æµ‹è¯•å›¾ç‰‡
        if test_img_path is None:
            test_img_path = './test_dataset/train/class_00/img_0000.png'
        
        if not os.path.exists(test_img_path):
            print(f"âŒ æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {test_img_path}")
            return
        
        # åŠ è½½å›¾ç‰‡
        original_img = Image.open(test_img_path).convert('RGB')
        img_tensor = transform(original_img).unsqueeze(0).to(self.device)
        
        # æµ‹è¯•ä¸åŒæ©ç æ¯”ä¾‹
        mask_ratios = [0.25, 0.5, 0.75, 0.9]
        
        fig, axes = plt.subplots(len(mask_ratios), 4, figsize=(16, len(mask_ratios)*4))
        
        reconstruction_stats = {}
        
        for i, mask_ratio in enumerate(mask_ratios):
            with torch.no_grad():
                loss, pred, mask = model(img_tensor, mask_ratio=mask_ratio)
                reconstructed = model.unpatchify(pred)
                
                # åˆ›å»ºæ©ç å¯è§†åŒ–
                mask_vis = mask.detach()
                mask_vis = mask_vis.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 * 3)
                mask_vis = model.unpatchify(mask_vis)
            
            # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼
            original_display = torch.clamp(inv_normalize(img_tensor[0]).cpu(), 0, 1)
            reconstructed_display = torch.clamp(inv_normalize(reconstructed[0]).cpu(), 0, 1)
            masked_img = original_display * (1 - mask_vis[0].cpu()) + mask_vis[0].cpu() * 0.5
            
            # è®¡ç®—é‡å»ºè¯¯å·®
            error = torch.abs(original_display - reconstructed_display)
            error_display = error.mean(dim=0)
            
            # æ˜¾ç¤ºç»“æœ
            axes[i, 0].imshow(original_display.permute(1, 2, 0))
            axes[i, 0].set_title('Original')
            axes[i, 0].axis('off')
            
            axes[i, 1].imshow(masked_img.permute(1, 2, 0))
            axes[i, 1].set_title(f'Masked ({mask_ratio*100:.0f}%)')
            axes[i, 1].axis('off')
            
            axes[i, 2].imshow(reconstructed_display.permute(1, 2, 0))
            axes[i, 2].set_title(f'Reconstructed\nLoss: {loss.item():.3f}')
            axes[i, 2].axis('off')
            
            im = axes[i, 3].imshow(error_display, cmap='hot')
            axes[i, 3].set_title('Reconstruction Error')
            axes[i, 3].axis('off')
            plt.colorbar(im, ax=axes[i, 3], fraction=0.046, pad=0.04)
            
            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
            reconstruction_stats[f'mask_{mask_ratio}'] = {
                'loss': loss.item(),
                'mask_ratio': mask_ratio,
                'mean_error': error.mean().item(),
                'max_error': error.max().item()
            }
            
            print(f"  æ©ç æ¯”ä¾‹ {mask_ratio*100:.0f}%: æŸå¤± {loss.item():.4f}, å¹³å‡è¯¯å·® {error.mean().item():.4f}")
        
        plt.tight_layout()
        
        # ä¿å­˜é‡å»ºç»“æœ
        recon_path = self.reconstruction_dir / 'mae_reconstruction_comparison.png'
        plt.savefig(recon_path, dpi=150, bbox_inches='tight')
        print(f"âœ… MAE é‡å»ºå¯¹æ¯”ä¿å­˜: {recon_path}")
        plt.close()
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_path = self.analysis_dir / 'reconstruction_stats.json'
        with open(stats_path, 'w') as f:
            json.dump(reconstruction_stats, f, indent=2)
        
        return reconstruction_stats

    def create_summary_report(self, training_stats=None, reconstruction_stats=None):
        """åˆ›å»ºæ€»ç»“æŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
        
        report_path = self.output_dir / 'experiment_summary.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# MAE å®éªŒç»“æœæŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**è®¾å¤‡**: {self.device}\n\n")
            
            # è®­ç»ƒç»Ÿè®¡
            if training_stats:
                f.write("## è®­ç»ƒç»Ÿè®¡\n\n")
                f.write(f"- è®­ç»ƒè½®æ•°: {training_stats['total_epochs']}\n")
                f.write(f"- åˆå§‹æŸå¤±: {training_stats['initial_loss']:.4f}\n")
                f.write(f"- æœ€ç»ˆæŸå¤±: {training_stats['final_loss']:.4f}\n")
                f.write(f"- æŸå¤±ä¸‹é™: {training_stats['loss_reduction']:.1f}%\n")
                f.write(f"- æœ€é«˜å­¦ä¹ ç‡: {training_stats['max_lr']:.2e}\n\n")
            
            # é‡å»ºç»Ÿè®¡
            if reconstruction_stats:
                f.write("## é‡å»ºæ€§èƒ½\n\n")
                f.write("| æ©ç æ¯”ä¾‹ | é‡å»ºæŸå¤± | å¹³å‡è¯¯å·® | æœ€å¤§è¯¯å·® |\n")
                f.write("|---------|---------|---------|----------|\n")
                for key, stats in reconstruction_stats.items():
                    mask_ratio = stats['mask_ratio']
                    f.write(f"| {mask_ratio*100:.0f}% | {stats['loss']:.4f} | {stats['mean_error']:.4f} | {stats['max_error']:.4f} |\n")
                f.write("\n")
            
            # æ–‡ä»¶åˆ—è¡¨
            f.write("## ç”Ÿæˆçš„æ–‡ä»¶\n\n")
            f.write("### è®­ç»ƒæ›²çº¿\n")
            f.write("- `training_curves/training_curves.png`: æŸå¤±å’Œå­¦ä¹ ç‡æ›²çº¿\n\n")
            
            f.write("### æ•°æ®é›†æ ·æœ¬\n")
            f.write("- `dataset_samples/dataset_samples_grid.png`: æ•°æ®é›†æ ·æœ¬ç½‘æ ¼\n")
            f.write("- `dataset_samples/*_sample.png`: å„ç±»åˆ«æ ·æœ¬\n\n")
            
            f.write("### é‡å»ºç»“æœ\n")
            f.write("- `reconstructions/mae_reconstruction_comparison.png`: ä¸åŒæ©ç æ¯”ä¾‹çš„é‡å»ºå¯¹æ¯”\n\n")
            
            f.write("### åˆ†ææ•°æ®\n")
            f.write("- `analysis/training_stats.json`: è®­ç»ƒç»Ÿè®¡æ•°æ®\n")
            f.write("- `analysis/reconstruction_stats.json`: é‡å»ºç»Ÿè®¡æ•°æ®\n\n")
        
        print(f"âœ… å®éªŒæŠ¥å‘Šä¿å­˜: {report_path}")

    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„ MAE å¯è§†åŒ–åˆ†æ...")
        print("=" * 60)
        
        # 1. åˆ†æè®­ç»ƒæ—¥å¿—
        training_stats = self.analyze_training_log()
        
        # 2. å±•ç¤ºæ•°æ®é›†æ ·æœ¬
        self.show_dataset_samples()
        
        # 3. MAE é‡å»ºå¯è§†åŒ–
        reconstruction_stats = self.visualize_mae_reconstruction()
        
        # 4. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.create_summary_report(training_stats, reconstruction_stats)
        
        print("\nğŸ‰ å®Œæ•´åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        
        # æ˜¾ç¤ºæ–‡ä»¶ç»“æ„
        self.show_file_structure()
        
        return self.output_dir

    def show_file_structure(self):
        """æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶ç»“æ„"""
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:")
        
        def print_tree(directory, prefix=""):
            items = sorted(directory.iterdir())
            for i, item in enumerate(items):
                is_last = i == len(items) - 1
                current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                print(f"{prefix}{current_prefix}{item.name}")
                
                if item.is_dir() and not item.name.startswith('.'):
                    extension = "    " if is_last else "â”‚   "
                    print_tree(item, prefix + extension)
        
        print_tree(self.output_dir)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ æœ‰ç»„ç»‡çš„ MAE å¯è§†åŒ–å·¥å…·")
    print("=" * 50)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = MAEVisualizer()
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    output_dir = visualizer.run_complete_analysis()
    
    print(f"\nğŸ’¡ æç¤º:")
    print(f"  - æŸ¥çœ‹å®éªŒæŠ¥å‘Š: open {output_dir}/experiment_summary.md")
    print(f"  - æµè§ˆæ‰€æœ‰å›¾ç‰‡: open {output_dir}")
    print(f"  - å¯¹æ¯”ä¸åŒå®éªŒ: ls {visualizer.base_output_dir}")

if __name__ == "__main__":
    main()


