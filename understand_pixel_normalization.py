#!/usr/bin/env python3
"""
ç†è§£MAEä¸­çš„åƒç´ å½’ä¸€åŒ–é—®é¢˜
è§£é‡Šå½’ä¸€åŒ–åƒç´  vs åŸå§‹åƒç´ ï¼Œä»¥åŠæ­£ç¡®çš„æ˜ å°„æ–¹æ³•
"""

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from datasets import load_dataset

# è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import models_mae

def explain_pixel_normalization():
    """è§£é‡Šåƒç´ å½’ä¸€åŒ–çš„æ¦‚å¿µ"""
    
    print("ğŸ“š åƒç´ å½’ä¸€åŒ–è¯¦è§£")
    print("=" * 60)
    
    print("\nğŸ¯ ä¸¤ç§è®­ç»ƒç›®æ ‡çš„åŒºåˆ«:")
    
    print("\n1ï¸âƒ£ åŸå§‹åƒç´  (norm_pix_loss=False):")
    print("   â€¢ ç›®æ ‡: ç›´æ¥é¢„æµ‹åŸå§‹çš„RGBåƒç´ å€¼")
    print("   â€¢ èŒƒå›´: [0, 1] (ToTensorå)")
    print("   â€¢ æŸå¤±: MSE(é¢„æµ‹åƒç´ , åŸå§‹åƒç´ )")
    print("   â€¢ ä¼˜ç‚¹: ç›´è§‚ï¼Œå®¹æ˜“ç†è§£")
    print("   â€¢ ç¼ºç‚¹: ä¸åŒpatchçš„åƒç´ å€¼å·®å¼‚å¾ˆå¤§")
    
    print("\n2ï¸âƒ£ å½’ä¸€åŒ–åƒç´  (norm_pix_loss=True):")
    print("   â€¢ ç›®æ ‡: é¢„æµ‹æ¯ä¸ªpatchå†…å½’ä¸€åŒ–çš„åƒç´ å€¼")
    print("   â€¢ èŒƒå›´: æ¯ä¸ªpatchå†…å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1")
    print("   â€¢ æŸå¤±: MSE(é¢„æµ‹åƒç´ , å½’ä¸€åŒ–åƒç´ )")
    print("   â€¢ ä¼˜ç‚¹: æ¶ˆé™¤äº†ä¸åŒpatché—´çš„äº®åº¦å·®å¼‚")
    print("   â€¢ ç¼ºç‚¹: éœ€è¦æ­£ç¡®çš„åå½’ä¸€åŒ–æ‰èƒ½å¯è§†åŒ–")

def demonstrate_normalization_difference():
    """æ¼”ç¤ºå½’ä¸€åŒ–çš„å…·ä½“å·®å¼‚"""
    print(f"\nğŸ§ª æ¼”ç¤ºå½’ä¸€åŒ–çš„å…·ä½“å·®å¼‚...")
    
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å›¾åƒ
    test_img = torch.zeros(3, 224, 224)
    
    # åˆ›å»ºä¸åŒäº®åº¦çš„åŒºåŸŸ
    test_img[:, 0:112, 0:112] = 0.2    # æš—åŒºåŸŸ
    test_img[:, 0:112, 112:224] = 0.8  # äº®åŒºåŸŸ
    test_img[:, 112:224, 0:112] = 0.5  # ä¸­ç­‰åŒºåŸŸ
    test_img[:, 112:224, 112:224] = 0.9 # å¾ˆäº®åŒºåŸŸ
    
    print(f"æµ‹è¯•å›¾åƒèŒƒå›´: [{test_img.min():.3f}, {test_img.max():.3f}]")
    
    # æ¨¡æ‹Ÿpatchå¤„ç† (ç®€åŒ–ç‰ˆ)
    patch_size = 16
    patches = []
    normalized_patches = []
    
    for i in range(0, 224, patch_size):
        for j in range(0, 224, patch_size):
            # æå–patch
            patch = test_img[:, i:i+patch_size, j:j+patch_size]
            patches.append(patch)
            
            # å½’ä¸€åŒ–patch (åœ¨æ¯ä¸ªpatchå†…)
            patch_flat = patch.flatten()
            if patch_flat.std() > 1e-6:  # é¿å…é™¤é›¶
                normalized_patch = (patch_flat - patch_flat.mean()) / patch_flat.std()
            else:
                normalized_patch = patch_flat - patch_flat.mean()
            
            normalized_patches.append(normalized_patch.reshape(patch.shape))
    
    # æ˜¾ç¤ºå‡ ä¸ªpatchçš„å·®å¼‚
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    
    for i in range(4):
        patch_idx = i * 30  # é€‰æ‹©ä¸åŒçš„patch
        if patch_idx < len(patches):
            original_patch = patches[patch_idx]
            normalized_patch = normalized_patches[patch_idx]
            
            # æ˜¾ç¤ºåŸå§‹patch
            axes[0, i].imshow(original_patch.permute(1, 2, 0))
            axes[0, i].set_title(f'Original Patch {i+1}\nMean: {original_patch.mean():.3f}')
            axes[0, i].axis('off')
            
            # æ˜¾ç¤ºå½’ä¸€åŒ–patch (éœ€è¦é‡æ–°æ˜ å°„åˆ°[0,1]ç”¨äºæ˜¾ç¤º)
            norm_patch_display = (normalized_patch - normalized_patch.min()) / (normalized_patch.max() - normalized_patch.min() + 1e-6)
            axes[1, i].imshow(norm_patch_display.permute(1, 2, 0))
            axes[1, i].set_title(f'Normalized Patch {i+1}\nMean: {normalized_patch.mean():.3f}')
            axes[1, i].axis('off')
    
    plt.tight_layout()
    plt.savefig('patch_normalization_demo.png', dpi=150, bbox_inches='tight')
    print("âœ… patchå½’ä¸€åŒ–æ¼”ç¤ºä¿å­˜: patch_normalization_demo.png")
    plt.close()

def test_correct_denormalization():
    """æµ‹è¯•æ­£ç¡®çš„åå½’ä¸€åŒ–æ–¹æ³•"""
    print(f"\nğŸ”§ æµ‹è¯•æ­£ç¡®çš„åå½’ä¸€åŒ–æ–¹æ³•...")
    
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    
    # åŠ è½½ä½¿ç”¨norm_pix_loss=Trueè®­ç»ƒçš„æ¨¡å‹
    model = models_mae.mae_vit_base_patch16(norm_pix_loss=True)
    
    checkpoint_path = './output_image_repair_v1/checkpoint-19.pth'
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        model.load_state_dict(checkpoint['model'])
        print("âœ… åŠ è½½norm_pix_loss=Trueæ¨¡å‹")
    
    model.to(device)
    model.eval()
    
    # åŠ è½½æµ‹è¯•å›¾ç‰‡
    try:
        ds = load_dataset("Mercity/AnimeDiffusion_Dataset")
        sample = ds['train'][0]
        original_img = sample['image']
        
        if original_img.mode != 'RGB':
            original_img = original_img.convert('RGB')
    except Exception as e:
        print(f"ä½¿ç”¨é»˜è®¤å›¾ç‰‡: {e}")
        original_img = Image.new('RGB', (224, 224), color='red')
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize(int(224 * 1.15), interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    img_tensor = transform(original_img).unsqueeze(0).to(device)
    
    # MAEå‰å‘ä¼ æ’­
    with torch.no_grad():
        loss, pred, mask = model(img_tensor, mask_ratio=0.25)
        
        print(f"é¢„æµ‹å€¼èŒƒå›´: [{pred.min():.3f}, {pred.max():.3f}]")
        
        # æ–¹æ³•1: æ ‡å‡†çš„unpatchify (æ¨¡å‹å†…ç½®)
        recon_standard = model.unpatchify(pred)
        print(f"æ ‡å‡†é‡å»ºèŒƒå›´: [{recon_standard.min():.3f}, {recon_standard.max():.3f}]")
        
        # æ–¹æ³•2: æ‰‹åŠ¨å¤„ç†å½’ä¸€åŒ–åƒç´ çš„åå½’ä¸€åŒ–
        recon_manual = manual_denormalize_patches(pred, img_tensor, mask, model)
        print(f"æ‰‹åŠ¨é‡å»ºèŒƒå›´: [{recon_manual.min():.3f}, {recon_manual.max():.3f}]")
    
    # æ˜¾ç¤ºä¸åŒæ–¹æ³•çš„ç»“æœ
    inv_normalize = transforms.Normalize(
        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
        std=[1/0.229, 1/0.224, 1/0.225]
    )
    
    original_display = torch.clamp(inv_normalize(img_tensor[0]).cpu(), 0, 1)
    recon_standard_display = torch.clamp(inv_normalize(recon_standard[0]).cpu(), 0, 1)
    recon_manual_display = torch.clamp(inv_normalize(recon_manual[0]).cpu(), 0, 1)
    
    # åˆ›å»ºæ©ç å¯è§†åŒ–
    mask_vis = mask.detach().unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 * 3)
    mask_vis = model.unpatchify(mask_vis)
    masked_img = original_display * (1 - mask_vis[0].cpu()) + mask_vis[0].cpu() * 0.5
    
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))
    
    axes[0].imshow(original_display.permute(1, 2, 0))
    axes[0].set_title('Original')
    axes[0].axis('off')
    
    axes[1].imshow(masked_img.permute(1, 2, 0))
    axes[1].set_title('25% Masked')
    axes[1].axis('off')
    
    axes[2].imshow(recon_standard_display.permute(1, 2, 0))
    axes[2].set_title(f'Standard Method\nLoss: {loss.item():.3f}')
    axes[2].axis('off')
    
    axes[3].imshow(recon_manual_display.permute(1, 2, 0))
    axes[3].set_title('Manual Denormalization\n(Experimental)')
    axes[3].axis('off')
    
    plt.tight_layout()
    plt.savefig('denormalization_methods_comparison.png', dpi=150, bbox_inches='tight')
    print("âœ… åå½’ä¸€åŒ–æ–¹æ³•å¯¹æ¯”ä¿å­˜: denormalization_methods_comparison.png")
    plt.close()

def manual_denormalize_patches(pred, original_img, mask, model):
    """æ‰‹åŠ¨å®ç°å½’ä¸€åŒ–åƒç´ çš„åå½’ä¸€åŒ–"""
    
    # è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„æ–¹æ³•ï¼Œå°è¯•æ­£ç¡®å¤„ç†å½’ä¸€åŒ–åƒç´ 
    B, L, D = pred.shape
    
    # è·å–patchä¿¡æ¯
    patch_size = model.patch_embed.patch_size[0]
    num_patches_per_dim = int(L**0.5)
    
    # é‡å»ºå›¾åƒ
    reconstructed = torch.zeros(B, 3, 224, 224, device=pred.device)
    
    # è·å–åŸå§‹å›¾åƒçš„patchç”¨äºè®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    original_patches = model.patchify(original_img)  # [B, L, patch_size^2 * 3]
    
    for i in range(L):
        if mask[0, i] == 1:  # åªå¤„ç†è¢«æ©ç›–çš„patch
            # è·å–é¢„æµ‹çš„å½’ä¸€åŒ–åƒç´ 
            pred_patch = pred[0, i]  # [D] where D = patch_size^2 * 3
            
            # è·å–å¯¹åº”çš„åŸå§‹patchç»Ÿè®¡ä¿¡æ¯
            original_patch = original_patches[0, i]
            patch_mean = original_patch.mean()
            patch_std = original_patch.std()
            
            # åå½’ä¸€åŒ–: normalized_pixel * std + mean
            if patch_std > 1e-6:
                denorm_patch = pred_patch * patch_std + patch_mean
            else:
                denorm_patch = pred_patch + patch_mean
            
            # å°†patchæ”¾å›å›¾åƒ
            h = i // num_patches_per_dim
            w = i % num_patches_per_dim
            
            patch_img = denorm_patch.reshape(3, patch_size, patch_size)
            reconstructed[0, :, h*patch_size:(h+1)*patch_size, w*patch_size:(w+1)*patch_size] = patch_img
    
    # å¯¹äºæœªè¢«æ©ç›–çš„patchï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åƒç´ 
    for i in range(L):
        if mask[0, i] == 0:  # æœªè¢«æ©ç›–çš„patch
            h = i // num_patches_per_dim
            w = i % num_patches_per_dim
            reconstructed[0, :, h*patch_size:(h+1)*patch_size, w*patch_size:(w+1)*patch_size] = \
                original_img[0, :, h*patch_size:(h+1)*patch_size, w*patch_size:(w+1)*patch_size]
    
    return reconstructed

def create_detailed_explanation():
    """åˆ›å»ºè¯¦ç»†çš„æŠ€æœ¯è§£é‡Š"""
    print(f"\nğŸ“– åˆ›å»ºè¯¦ç»†æŠ€æœ¯è§£é‡Š...")
    
    explanation = """
# MAE åƒç´ å½’ä¸€åŒ–æŠ€æœ¯è§£é‡Š

## é—®é¢˜çš„æ ¹æº

ä½ è§‚å¯Ÿåˆ°çš„é‡å»ºæ¨¡ç³Šé—®é¢˜ï¼Œæ ¸å¿ƒåœ¨äº **norm_pix_loss** å‚æ•°çš„ç†è§£å’Œå¤„ç†ã€‚

### 1. åŸå§‹åƒç´  (norm_pix_loss=False)

```python
# è®­ç»ƒç›®æ ‡ï¼šç›´æ¥é¢„æµ‹åŸå§‹åƒç´ å€¼
target = original_pixels  # èŒƒå›´ [0, 1]
loss = MSE(predicted_pixels, target)
```

**ç‰¹ç‚¹**:
- âœ… ç›´è§‚æ˜“æ‡‚
- âœ… å¯è§†åŒ–ç®€å•
- âŒ ä¸åŒpatché—´äº®åº¦å·®å¼‚å¤§ï¼Œè®­ç»ƒå›°éš¾

### 2. å½’ä¸€åŒ–åƒç´  (norm_pix_loss=True)

```python
# è®­ç»ƒç›®æ ‡ï¼šé¢„æµ‹æ¯ä¸ªpatchå†…å½’ä¸€åŒ–çš„åƒç´ å€¼
for each_patch:
    patch_mean = patch.mean()
    patch_std = patch.std()
    normalized_patch = (patch - patch_mean) / patch_std
    
target = normalized_patches  # æ¯ä¸ªpatchå†…å‡å€¼â‰ˆ0ï¼Œæ ‡å‡†å·®â‰ˆ1
loss = MSE(predicted_normalized_pixels, target)
```

**ç‰¹ç‚¹**:
- âœ… æ¶ˆé™¤patché—´äº®åº¦å·®å¼‚
- âœ… è®­ç»ƒæ›´ç¨³å®š
- âŒ åå½’ä¸€åŒ–å¤æ‚
- âŒ å®¹æ˜“å‡ºç°å¯è§†åŒ–é”™è¯¯

## æ­£ç¡®çš„åå½’ä¸€åŒ–æ–¹æ³•

### å½“å‰çš„é”™è¯¯åšæ³•
```python
# é”™è¯¯ï¼šç›´æ¥ç”¨å…¨å›¾çš„å½’ä¸€åŒ–å‚æ•°
reconstructed = model.unpatchify(pred)  # è¿™é‡Œæœ‰é—®é¢˜ï¼
display = inv_normalize(reconstructed)  # é”™è¯¯çš„åå½’ä¸€åŒ–
```

### æ­£ç¡®çš„åšæ³•
```python
# æ­£ç¡®ï¼šéœ€è¦ç”¨æ¯ä¸ªpatchçš„ç»Ÿè®¡ä¿¡æ¯åå½’ä¸€åŒ–
for each_masked_patch:
    # 1. è·å–åŸå§‹patchçš„ç»Ÿè®¡ä¿¡æ¯
    original_patch_mean = original_patch.mean()
    original_patch_std = original_patch.std()
    
    # 2. åå½’ä¸€åŒ–é¢„æµ‹å€¼
    denormalized_patch = pred_patch * original_patch_std + original_patch_mean
    
    # 3. æ”¾å›å¯¹åº”ä½ç½®
    reconstructed[patch_position] = denormalized_patch
```

## ä¸ºä»€ä¹ˆä¼šå‡ºç°å™ªå£°

1. **ç»Ÿè®¡ä¿¡æ¯ä¸¢å¤±**: æ¨¡å‹é¢„æµ‹çš„æ˜¯å½’ä¸€åŒ–åƒç´ ï¼Œä½†åå½’ä¸€åŒ–æ—¶ç”¨é”™äº†ç»Ÿè®¡ä¿¡æ¯
2. **patché—´ä¸è¿ç»­**: æ¯ä¸ªpatchç‹¬ç«‹å½’ä¸€åŒ–ï¼Œè¾¹ç•Œå¯èƒ½ä¸è¿ç»­
3. **è®­ç»ƒç›®æ ‡ä¸åŒ¹é…**: æ¨¡å‹å­¦ä¹ çš„ç›®æ ‡å’Œæ˜¾ç¤ºæ—¶çš„å¤„ç†ä¸ä¸€è‡´

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆA: ä½¿ç”¨åŸå§‹åƒç´ è®­ç»ƒ (æ¨è)
```bash
# ç®€å•æœ‰æ•ˆï¼Œç›´æ¥é¢„æµ‹åŸå§‹åƒç´ 
python main_pretrain_animediffusion.py --norm_pix_loss=False
```

### æ–¹æ¡ˆB: æ­£ç¡®å¤„ç†å½’ä¸€åŒ–åƒç´ 
éœ€è¦ä¿®æ”¹unpatchifyå‡½æ•°ï¼Œæ­£ç¡®å¤„ç†æ¯ä¸ªpatchçš„åå½’ä¸€åŒ–ã€‚

### æ–¹æ¡ˆC: æ··åˆæ–¹æ³•
åœ¨è®­ç»ƒæ—¶ä½¿ç”¨å½’ä¸€åŒ–åƒç´ ï¼Œä½†åœ¨æ¨ç†æ—¶ç‰¹æ®Šå¤„ç†åå½’ä¸€åŒ–ã€‚
"""
    
    with open('pixel_normalization_explanation.md', 'w') as f:
        f.write(explanation)
    
    print("âœ… æŠ€æœ¯è§£é‡Šä¿å­˜: pixel_normalization_explanation.md")

def test_correct_reconstruction_method():
    """æµ‹è¯•æ­£ç¡®çš„é‡å»ºæ–¹æ³•"""
    print(f"\nğŸ§ª æµ‹è¯•æ­£ç¡®çš„é‡å»ºæ–¹æ³•...")
    
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    
    # åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„MAEæ¨¡å‹ï¼Œå®ç°æ­£ç¡®çš„åå½’ä¸€åŒ–
    class FixedMAE(models_mae.MaskedAutoencoderViT):
        def forward_decoder(self, x, ids_restore):
            # æ ‡å‡†çš„decoderå‰å‘ä¼ æ’­
            x = self.decoder_embed(x)
            
            # æ·»åŠ mask tokens
            mask_tokens = self.mask_token.repeat(x.shape[0], ids_restore.shape[1] + 1 - x.shape[1], 1)
            x_ = torch.cat([x[:, 1:, :], mask_tokens], dim=1)
            x_ = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[2]))
            x = torch.cat([x[:, :1, :], x_], dim=1)
            
            # æ·»åŠ ä½ç½®ç¼–ç 
            x = x + self.decoder_pos_embed
            
            # åº”ç”¨decoder blocks
            for blk in self.decoder_blocks:
                x = blk(x)
            x = self.decoder_norm(x)
            
            # é¢„æµ‹åƒç´ 
            x = self.decoder_pred(x)
            x = x[:, 1:, :]  # ç§»é™¤class token
            
            return x
        
        def unpatchify_corrected(self, x, original_img, mask):
            """æ­£ç¡®çš„unpatchifyï¼Œå¤„ç†å½’ä¸€åŒ–åƒç´ """
            B, L, D = x.shape
            p = self.patch_embed.patch_size[0]
            h = w = int(L**.5)
            
            x = x.reshape(shape=(B, h, w, p, p, 3))
            x = torch.einsum('nhwpqc->nchpwq', x)
            imgs = x.reshape(shape=(B, 3, h * p, w * p))
            
            if self.norm_pix_loss:
                # å¦‚æœä½¿ç”¨å½’ä¸€åŒ–åƒç´ æŸå¤±ï¼Œéœ€è¦æ­£ç¡®çš„åå½’ä¸€åŒ–
                original_patches = self.patchify(original_img)
                
                for i in range(L):
                    if mask[0, i] == 1:  # åªå¤„ç†è¢«æ©ç›–çš„patch
                        # è·å–åŸå§‹patchçš„ç»Ÿè®¡ä¿¡æ¯
                        original_patch = original_patches[0, i]
                        patch_mean = original_patch.mean()
                        patch_std = original_patch.std()
                        
                        # åå½’ä¸€åŒ–
                        h_idx = i // w
                        w_idx = i % w
                        
                        if patch_std > 1e-6:
                            imgs[0, :, h_idx*p:(h_idx+1)*p, w_idx*p:(w_idx+1)*p] = \
                                imgs[0, :, h_idx*p:(h_idx+1)*p, w_idx*p:(w_idx+1)*p] * patch_std + patch_mean
                        else:
                            imgs[0, :, h_idx*p:(h_idx+1)*p, w_idx*p:(w_idx+1)*p] = \
                                imgs[0, :, h_idx*p:(h_idx+1)*p, w_idx*p:(w_idx+1)*p] + patch_mean
            
            return imgs
    
    # æµ‹è¯•ä¿®æ­£çš„æ–¹æ³•
    fixed_model = FixedMAE(norm_pix_loss=True)
    fixed_model.load_state_dict(model.state_dict())
    fixed_model.to(device)
    fixed_model.eval()
    
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    img_tensor = transform(original_img).unsqueeze(0).to(device)
    
    with torch.no_grad():
        loss, pred, mask = fixed_model(img_tensor, mask_ratio=0.25)
        
        # æ ‡å‡†æ–¹æ³•
        recon_standard = fixed_model.unpatchify(pred)
        
        # ä¿®æ­£æ–¹æ³•
        recon_corrected = fixed_model.unpatchify_corrected(pred, img_tensor, mask)
    
    # å¯è§†åŒ–å¯¹æ¯”
    inv_normalize = transforms.Normalize(
        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
        std=[1/0.229, 1/0.224, 1/0.225]
    )
    
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))
    
    original_display = torch.clamp(inv_normalize(img_tensor[0]).cpu(), 0, 1)
    standard_display = torch.clamp(inv_normalize(recon_standard[0]).cpu(), 0, 1)
    corrected_display = torch.clamp(inv_normalize(recon_corrected[0]).cpu(), 0, 1)
    
    axes[0].imshow(original_display.permute(1, 2, 0))
    axes[0].set_title('Original')
    axes[0].axis('off')
    
    axes[1].imshow(standard_display.permute(1, 2, 0))
    axes[1].set_title('Standard Unpatchify\n(Current Method)')
    axes[1].axis('off')
    
    axes[2].imshow(corrected_display.permute(1, 2, 0))
    axes[2].set_title('Corrected Unpatchify\n(Fixed Method)')
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.savefig('corrected_reconstruction_test.png', dpi=150, bbox_inches='tight')
    print("âœ… ä¿®æ­£é‡å»ºæ–¹æ³•æµ‹è¯•ä¿å­˜: corrected_reconstruction_test.png")
    plt.close()
    
    # è®¡ç®—è´¨é‡æŒ‡æ ‡
    mse_standard = torch.mean((original_display - standard_display)**2).item()
    mse_corrected = torch.mean((original_display - corrected_display)**2).item()
    
    psnr_standard = 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse_standard))).item()
    psnr_corrected = 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse_corrected))).item()
    
    print(f"\nğŸ“Š æ–¹æ³•å¯¹æ¯”:")
    print(f"  æ ‡å‡†æ–¹æ³•: PSNR {psnr_standard:.1f}dB, MSE {mse_standard:.4f}")
    print(f"  ä¿®æ­£æ–¹æ³•: PSNR {psnr_corrected:.1f}dB, MSE {mse_corrected:.4f}")
    print(f"  æ”¹è¿›: {psnr_corrected - psnr_standard:+.1f}dB")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š MAEåƒç´ å½’ä¸€åŒ–é—®é¢˜æ·±åº¦è§£æ")
    print("=" * 50)
    
    # 1. è§£é‡Šæ¦‚å¿µ
    explain_pixel_normalization()
    
    # 2. æ¼”ç¤ºå·®å¼‚
    demonstrate_normalization_difference()
    
    # 3. åˆ›å»ºæŠ€æœ¯è§£é‡Š
    create_detailed_explanation()
    
    # 4. æµ‹è¯•æ­£ç¡®çš„åå½’ä¸€åŒ–
    test_correct_reconstruction_method()
    
    print(f"\nğŸ¯ æ€»ç»“:")
    print(f"  ğŸ”´ å½“å‰é—®é¢˜: norm_pix_loss=Trueæ—¶åå½’ä¸€åŒ–ä¸æ­£ç¡®")
    print(f"  ğŸŸ¡ ä¸´æ—¶è§£å†³: ä½¿ç”¨norm_pix_loss=False")
    print(f"  ğŸŸ¢ æ ¹æœ¬è§£å†³: å®ç°æ­£ç¡®çš„patchçº§åå½’ä¸€åŒ–")

if __name__ == "__main__":
    main()


