#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆ MAE å¯è§†åŒ–å·¥å…·
å±•ç¤ºè®­ç»ƒç»“æœå’Œæ¨¡å‹é‡å»ºæ•ˆæœ
"""

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import json

# è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import models_mae

def visualize_mae_with_random_model():
    """ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹å±•ç¤º MAE å·¥ä½œåŸç†"""
    print("ğŸ¨ ä½¿ç”¨éšæœºæ¨¡å‹å±•ç¤º MAE é‡å»ºè¿‡ç¨‹")
    
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = models_mae.mae_vit_base_patch16(norm_pix_loss=True)
    model.to(device)
    model.eval()
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    inv_normalize = transforms.Normalize(
        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
        std=[1/0.229, 1/0.224, 1/0.225]
    )
    
    # æ‰¾ä¸€å¼ æµ‹è¯•å›¾ç‰‡
    test_img_path = './test_dataset/train/class_00/img_0000.png'
    if not os.path.exists(test_img_path):
        print(f"âŒ æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {test_img_path}")
        return
    
    # åŠ è½½å›¾ç‰‡
    original_img = Image.open(test_img_path).convert('RGB')
    img_tensor = transform(original_img).unsqueeze(0).to(device)
    
    # æµ‹è¯•ä¸åŒçš„æ©ç æ¯”ä¾‹
    mask_ratios = [0.5, 0.75, 0.9]
    
    fig, axes = plt.subplots(len(mask_ratios), 3, figsize=(12, len(mask_ratios)*4))
    
    for i, mask_ratio in enumerate(mask_ratios):
        with torch.no_grad():
            loss, pred, mask = model(img_tensor, mask_ratio=mask_ratio)
            reconstructed = model.unpatchify(pred)
            
            # åˆ›å»ºæ©ç å¯è§†åŒ–
            mask_vis = mask.detach()
            mask_vis = mask_vis.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 * 3)
            mask_vis = model.unpatchify(mask_vis)
        
        # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼
        original_display = torch.clamp(inv_normalize(img_tensor[0]).cpu(), 0, 1)
        reconstructed_display = torch.clamp(inv_normalize(reconstructed[0]).cpu(), 0, 1)
        masked_img = original_display * (1 - mask_vis[0].cpu()) + mask_vis[0].cpu() * 0.5
        
        # æ˜¾ç¤ºç»“æœ
        if len(mask_ratios) == 1:
            ax_row = axes
        else:
            ax_row = axes[i]
            
        ax_row[0].imshow(original_display.permute(1, 2, 0))
        ax_row[0].set_title('Original Image')
        ax_row[0].axis('off')
        
        ax_row[1].imshow(masked_img.permute(1, 2, 0))
        ax_row[1].set_title(f'Masked ({mask_ratio*100:.0f}% hidden)')
        ax_row[1].axis('off')
        
        ax_row[2].imshow(reconstructed_display.permute(1, 2, 0))
        ax_row[2].set_title(f'Reconstructed\nLoss: {loss.item():.3f}')
        ax_row[2].axis('off')
        
        print(f"  æ©ç æ¯”ä¾‹ {mask_ratio*100:.0f}%: æŸå¤± {loss.item():.4f}")
    
    plt.tight_layout()
    plt.savefig('mae_reconstruction_demo.png', dpi=150, bbox_inches='tight')
    print("âœ… MAE é‡å»ºæ¼”ç¤ºä¿å­˜: mae_reconstruction_demo.png")
    plt.show()

def analyze_training_log():
    """åˆ†æè®­ç»ƒæ—¥å¿—"""
    print("ğŸ“Š åˆ†æè®­ç»ƒæ—¥å¿—")
    
    log_file = './output_m4/log.txt'
    if not os.path.exists(log_file):
        print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return
    
    epochs = []
    losses = []
    lrs = []
    
    with open(log_file, 'r') as f:
        for line in f:
            try:
                data = json.loads(line.strip())
                epochs.append(data['epoch'])
                losses.append(data['train_loss'])
                lrs.append(data.get('train_lr', 0))
            except:
                continue
    
    if not epochs:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
        return
    
    print(f"ğŸ“ˆ è®­ç»ƒç»Ÿè®¡:")
    print(f"  è®­ç»ƒè½®æ•°: {len(epochs)}")
    print(f"  åˆå§‹æŸå¤±: {losses[0]:.4f}")
    print(f"  æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
    print(f"  æŸå¤±ä¸‹é™: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%")
    print(f"  æœ€é«˜å­¦ä¹ ç‡: {max(lrs):.2e}")
    
    return epochs, losses, lrs

def show_test_dataset_samples():
    """å±•ç¤ºæµ‹è¯•æ•°æ®é›†æ ·æœ¬"""
    print("ğŸ–¼ï¸  å±•ç¤ºæµ‹è¯•æ•°æ®é›†æ ·æœ¬")
    
    test_dir = './test_dataset/train'
    if not os.path.exists(test_dir):
        print(f"âŒ æµ‹è¯•æ•°æ®é›†ä¸å­˜åœ¨: {test_dir}")
        return
    
    # æ”¶é›†æ¯ä¸ªç±»åˆ«çš„ç¬¬ä¸€å¼ å›¾ç‰‡
    class_samples = []
    class_names = sorted(os.listdir(test_dir))
    
    for class_name in class_names[:5]:  # æœ€å¤š5ä¸ªç±»åˆ«
        class_path = os.path.join(test_dir, class_name)
        if os.path.isdir(class_path):
            img_files = sorted(os.listdir(class_path))
            if img_files:
                img_path = os.path.join(class_path, img_files[0])
                class_samples.append((class_name, img_path))
    
    if not class_samples:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return
    
    # åˆ›å»ºå¯è§†åŒ–
    n_samples = len(class_samples)
    fig, axes = plt.subplots(1, n_samples, figsize=(n_samples*3, 3))
    
    if n_samples == 1:
        axes = [axes]
    
    for i, (class_name, img_path) in enumerate(class_samples):
        try:
            img = Image.open(img_path).convert('RGB')
            axes[i].imshow(img)
            axes[i].set_title(f'{class_name}')
            axes[i].axis('off')
        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
    
    plt.tight_layout()
    plt.savefig('test_dataset_samples.png', dpi=150, bbox_inches='tight')
    print("âœ… æ•°æ®é›†æ ·æœ¬ä¿å­˜: test_dataset_samples.png")
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ MAE ç®€åŒ–å¯è§†åŒ–å·¥å…·")
    print("=" * 50)
    
    # 1. åˆ†æè®­ç»ƒæ—¥å¿—
    training_stats = analyze_training_log()
    
    # 2. å±•ç¤ºæ•°æ®é›†æ ·æœ¬
    show_test_dataset_samples()
    
    # 3. MAE é‡å»ºæ¼”ç¤º
    visualize_mae_with_random_model()
    
    print("\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - training_curves.png: è®­ç»ƒæ›²çº¿")
    print("  - test_dataset_samples.png: æ•°æ®é›†æ ·æœ¬")
    print("  - mae_reconstruction_demo.png: MAE é‡å»ºæ¼”ç¤º")
    
    # 4. æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    print("\nğŸ“ å½“å‰ç›®å½•çš„å¯è§†åŒ–æ–‡ä»¶:")
    import glob
    png_files = glob.glob("*.png")
    for png_file in sorted(png_files):
        size = os.path.getsize(png_file) / 1024  # KB
        print(f"  {png_file}: {size:.1f} KB")

if __name__ == "__main__":
    main()


