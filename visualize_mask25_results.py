#!/usr/bin/env python3
"""
25% æ©ç æ¯”ä¾‹å®éªŒç»“æœå¯è§†åŒ–
å¯¹æ¯”ä¸åŒæ©ç æ¯”ä¾‹çš„è®­ç»ƒæ•ˆæœ
"""

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import json
from datetime import datetime
from pathlib import Path
from datasets import load_dataset

# è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import models_mae

class Mask25Visualizer:
    def __init__(self):
        """åˆå§‹åŒ–25%æ©ç å®éªŒå¯è§†åŒ–å™¨"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path(f"./mask25_visualization_{timestamp}")
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“ 25%æ©ç å®éªŒç»“æœä¿å­˜åˆ°: {self.output_dir}")
        
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        
        # åŠ è½½25%æ©ç è®­ç»ƒçš„æ¨¡å‹
        self.model_25 = self._load_model('./output_animediffusion_mask25/checkpoint-9.pth', "25% mask model")
        
        # åŠ è½½75%æ©ç è®­ç»ƒçš„æ¨¡å‹ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        self.model_75 = self._load_model('./output_animediffusion/checkpoint-4.pth', "75% mask model")
        
        # åŠ è½½æ•°æ®é›†
        self.dataset = self._load_dataset()
        
        # å›¾åƒå˜æ¢
        self.transform = transforms.Compose([
            transforms.Resize(int(224 * 1.15), interpolation=transforms.InterpolationMode.BICUBIC),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        self.inv_normalize = transforms.Normalize(
            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
            std=[1/0.229, 1/0.224, 1/0.225]
        )

    def _load_model(self, checkpoint_path, description):
        """åŠ è½½æ¨¡å‹"""
        print(f"ğŸ¤– åŠ è½½ {description}...")
        
        model = models_mae.mae_vit_base_patch16(norm_pix_loss=True)
        
        if os.path.exists(checkpoint_path):
            try:
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
                model.load_state_dict(checkpoint['model'])
                epoch = checkpoint.get('epoch', 'unknown')
                print(f"âœ… {description} åŠ è½½æˆåŠŸ (epoch: {epoch})")
            except Exception as e:
                print(f"âš ï¸  {description} åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"âš ï¸  {description} checkpointä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºæ¨¡å‹")
        
        model.to(self.device)
        model.eval()
        return model

    def _load_dataset(self):
        """åŠ è½½AnimeDiffusionæ•°æ®é›†"""
        try:
            ds = load_dataset("Mercity/AnimeDiffusion_Dataset")
            return ds['train']
        except Exception as e:
            print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
            return None

    def compare_mask_ratios_on_same_images(self):
        """åœ¨ç›¸åŒå›¾ç‰‡ä¸Šå¯¹æ¯”ä¸åŒæ©ç æ¯”ä¾‹çš„æ•ˆæœ"""
        print(f"\nğŸ­ å¯¹æ¯”25%å’Œ75%æ©ç åœ¨ç›¸åŒå›¾ç‰‡ä¸Šçš„æ•ˆæœ...")
        
        if self.dataset is None:
            return
        
        # é€‰æ‹©å‡ å¼ æµ‹è¯•å›¾ç‰‡
        test_indices = [0, 100, 200, 300, 400, 500]
        
        fig, axes = plt.subplots(len(test_indices), 5, figsize=(20, len(test_indices)*3))
        
        comparison_stats = []
        
        for i, idx in enumerate(test_indices):
            try:
                sample = self.dataset[idx]
                original_img = sample['image']
                
                if original_img.mode != 'RGB':
                    original_img = original_img.convert('RGB')
                
                img_tensor = self.transform(original_img).unsqueeze(0).to(self.device)
                
                # åŸå›¾
                original_display = torch.clamp(self.inv_normalize(img_tensor[0]).cpu(), 0, 1)
                axes[i, 0].imshow(original_display.permute(1, 2, 0))
                axes[i, 0].set_title(f'Original {i+1}')
                axes[i, 0].axis('off')
                
                # 25%æ©ç ç»“æœ
                with torch.no_grad():
                    loss_25, pred_25, mask_25 = self.model_25(img_tensor, mask_ratio=0.25)
                    recon_25 = self.model_25.unpatchify(pred_25)
                    
                    # æ©ç å¯è§†åŒ–
                    mask_vis_25 = mask_25.detach().unsqueeze(-1).repeat(1, 1, self.model_25.patch_embed.patch_size[0]**2 * 3)
                    mask_vis_25 = self.model_25.unpatchify(mask_vis_25)
                
                masked_25 = original_display * (1 - mask_vis_25[0].cpu()) + mask_vis_25[0].cpu() * 0.5
                recon_display_25 = torch.clamp(self.inv_normalize(recon_25[0]).cpu(), 0, 1)
                
                axes[i, 1].imshow(masked_25.permute(1, 2, 0))
                axes[i, 1].set_title('25% Masked')
                axes[i, 1].axis('off')
                
                axes[i, 2].imshow(recon_display_25.permute(1, 2, 0))
                axes[i, 2].set_title(f'25% Recon\nLoss: {loss_25.item():.3f}')
                axes[i, 2].axis('off')
                
                # 75%æ©ç ç»“æœ
                with torch.no_grad():
                    loss_75, pred_75, mask_75 = self.model_75(img_tensor, mask_ratio=0.75)
                    recon_75 = self.model_75.unpatchify(pred_75)
                    
                    mask_vis_75 = mask_75.detach().unsqueeze(-1).repeat(1, 1, self.model_75.patch_embed.patch_size[0]**2 * 3)
                    mask_vis_75 = self.model_75.unpatchify(mask_vis_75)
                
                masked_75 = original_display * (1 - mask_vis_75[0].cpu()) + mask_vis_75[0].cpu() * 0.5
                recon_display_75 = torch.clamp(self.inv_normalize(recon_75[0]).cpu(), 0, 1)
                
                axes[i, 3].imshow(masked_75.permute(1, 2, 0))
                axes[i, 3].set_title('75% Masked')
                axes[i, 3].axis('off')
                
                axes[i, 4].imshow(recon_display_75.permute(1, 2, 0))
                axes[i, 4].set_title(f'75% Recon\nLoss: {loss_75.item():.3f}')
                axes[i, 4].axis('off')
                
                # è®°å½•ç»Ÿè®¡
                comparison_stats.append({
                    'index': idx,
                    'loss_25': loss_25.item(),
                    'loss_75': loss_75.item(),
                    'improvement': loss_25.item() - loss_75.item()
                })
                
                print(f"  å›¾ç‰‡ {i+1}: 25%æ©ç æŸå¤± {loss_25.item():.4f}, 75%æ©ç æŸå¤± {loss_75.item():.4f}")
                
            except Exception as e:
                print(f"å¤„ç†å›¾ç‰‡ {idx} æ—¶å‡ºé”™: {e}")
                for j in range(5):
                    axes[i, j].text(0.5, 0.5, f'Error', ha='center', va='center')
                    axes[i, j].axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜å¯¹æ¯”ç»“æœ
        comparison_path = self.output_dir / 'mask_ratio_comparison.png'
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        print(f"âœ… æ©ç æ¯”ä¾‹å¯¹æ¯”ä¿å­˜: {comparison_path}")
        plt.close()
        
        # åˆ†æç»Ÿè®¡ç»“æœ
        if comparison_stats:
            losses_25 = [stat['loss_25'] for stat in comparison_stats]
            losses_75 = [stat['loss_75'] for stat in comparison_stats]
            
            print(f"\nğŸ“Š æ©ç æ¯”ä¾‹å¯¹æ¯”ç»Ÿè®¡:")
            print(f"  25%æ©ç å¹³å‡æŸå¤±: {np.mean(losses_25):.4f}")
            print(f"  75%æ©ç å¹³å‡æŸå¤±: {np.mean(losses_75):.4f}")
            print(f"  å¹³å‡å·®å¼‚: {np.mean(losses_25) - np.mean(losses_75):.4f}")
            
            # ä¿å­˜ç»Ÿè®¡æ•°æ®
            stats_path = self.output_dir / 'mask_comparison_stats.json'
            with open(stats_path, 'w') as f:
                json.dump({
                    'mask_25_avg': float(np.mean(losses_25)),
                    'mask_75_avg': float(np.mean(losses_75)),
                    'difference': float(np.mean(losses_25) - np.mean(losses_75)),
                    'samples': comparison_stats
                }, f, indent=2)

    def analyze_training_curves(self):
        """åˆ†æ25%æ©ç çš„è®­ç»ƒæ›²çº¿"""
        print(f"\nğŸ“ˆ åˆ†æ25%æ©ç è®­ç»ƒæ›²çº¿...")
        
        log_file = './output_animediffusion_mask25/log.txt'
        
        if not os.path.exists(log_file):
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            return
        
        epochs, losses, lrs = [], [], []
        
        with open(log_file, 'r') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    epochs.append(data['epoch'])
                    losses.append(data['train_loss'])
                    lrs.append(data.get('train_lr', 0))
                except:
                    continue
        
        if not epochs:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆè®­ç»ƒæ•°æ®")
            return
        
        # åˆ›å»ºè®­ç»ƒæ›²çº¿
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
        
        # æŸå¤±æ›²çº¿
        ax1.plot(epochs, losses, 'g-', linewidth=3, marker='o', markersize=6)
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Training Loss')
        ax1.set_title('25% Mask Ratio Training Loss')
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ å…³é”®ç‚¹æ ‡æ³¨
        ax1.annotate(f'Start: {losses[0]:.3f}', xy=(epochs[0], losses[0]), 
                    xytext=(10, 10), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))
        ax1.annotate(f'End: {losses[-1]:.3f}', xy=(epochs[-1], losses[-1]), 
                    xytext=(10, 10), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))
        
        # å­¦ä¹ ç‡æ›²çº¿
        ax2.plot(epochs, lrs, 'r-', linewidth=2, marker='s', markersize=4)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.set_title('Learning Rate Schedule (25% Mask)')
        ax2.grid(True, alpha=0.3)
        ax2.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        plt.tight_layout()
        
        # ä¿å­˜æ›²çº¿
        curve_path = self.output_dir / 'mask25_training_curves.png'
        plt.savefig(curve_path, dpi=150, bbox_inches='tight')
        print(f"âœ… 25%æ©ç è®­ç»ƒæ›²çº¿ä¿å­˜: {curve_path}")
        plt.close()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"ğŸ“Š 25%æ©ç è®­ç»ƒç»Ÿè®¡:")
        print(f"  è®­ç»ƒè½®æ•°: {len(epochs)}")
        print(f"  åˆå§‹æŸå¤±: {losses[0]:.4f}")
        print(f"  æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
        print(f"  æŸå¤±ä¸‹é™: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%")
        print(f"  æœ€é«˜å­¦ä¹ ç‡: {max(lrs):.2e}")

    def create_comprehensive_comparison(self):
        """åˆ›å»ºå…¨é¢çš„æ©ç æ¯”ä¾‹å¯¹æ¯”"""
        print(f"\nğŸ“Š åˆ›å»ºå…¨é¢çš„æ©ç æ¯”ä¾‹å¯¹æ¯”...")
        
        # è¯»å–ä¸åŒå®éªŒçš„æ—¥å¿—
        experiments = [
            {
                'name': '25% Mask (Easy)',
                'log_file': './output_animediffusion_mask25/log.txt',
                'color': 'green',
                'marker': 'o',
                'description': 'åªæ©ç›–25%ï¼Œé‡å»ºä»»åŠ¡è¾ƒç®€å•'
            },
            {
                'name': '75% Mask (Hard)',
                'log_file': './output_animediffusion/log.txt',
                'color': 'blue',
                'marker': '^',
                'description': 'æ©ç›–75%ï¼Œé‡å»ºä»»åŠ¡è¾ƒå›°éš¾'
            }
        ]
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        all_data = []
        
        for exp in experiments:
            if os.path.exists(exp['log_file']):
                epochs, losses, lrs = [], [], []
                
                with open(exp['log_file'], 'r') as f:
                    for line in f:
                        try:
                            data = json.loads(line.strip())
                            epochs.append(data['epoch'])
                            losses.append(data['train_loss'])
                            lrs.append(data.get('train_lr', 0))
                        except:
                            continue
                
                if epochs and losses:
                    # æŸå¤±æ›²çº¿
                    ax1.plot(epochs, losses, color=exp['color'], marker=exp['marker'], 
                            linewidth=2, markersize=6, label=f"{exp['name']} (final: {losses[-1]:.3f})")
                    
                    # å­¦ä¹ ç‡æ›²çº¿
                    ax2.plot(epochs, lrs, color=exp['color'], marker=exp['marker'], 
                            linewidth=2, markersize=4, label=exp['name'])
                    
                    all_data.append({
                        'name': exp['name'],
                        'final_loss': losses[-1],
                        'initial_loss': losses[0],
                        'improvement': ((losses[0] - losses[-1]) / losses[0] * 100),
                        'epochs': len(epochs),
                        'max_lr': max(lrs) if lrs else 0
                    })
        
        # è®¾ç½®å›¾è¡¨
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Training Loss')
        ax1.set_title('Training Loss: 25% vs 75% Mask Ratio')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.set_title('Learning Rate Schedule Comparison')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        # æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾
        if len(all_data) >= 2:
            names = [data['name'] for data in all_data]
            final_losses = [data['final_loss'] for data in all_data]
            improvements = [data['improvement'] for data in all_data]
            
            # æœ€ç»ˆæŸå¤±å¯¹æ¯”
            bars1 = ax3.bar(names, final_losses, color=['green', 'blue'], alpha=0.7)
            ax3.set_ylabel('Final Loss')
            ax3.set_title('Final Loss Comparison')
            ax3.grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, loss in zip(bars1, final_losses):
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{loss:.3f}', ha='center', va='bottom', fontweight='bold')
            
            # æ”¹è¿›ç™¾åˆ†æ¯”å¯¹æ¯”
            bars2 = ax4.bar(names, improvements, color=['green', 'blue'], alpha=0.7)
            ax4.set_ylabel('Loss Reduction (%)')
            ax4.set_title('Training Improvement Comparison')
            ax4.grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, improvement in zip(bars2, improvements):
                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{improvement:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜ç»¼åˆå¯¹æ¯”
        comprehensive_path = self.output_dir / 'comprehensive_mask_comparison.png'
        plt.savefig(comprehensive_path, dpi=150, bbox_inches='tight')
        print(f"âœ… ç»¼åˆå¯¹æ¯”ä¿å­˜: {comprehensive_path}")
        plt.close()
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        if all_data:
            print(f"\nğŸ“Š æ©ç æ¯”ä¾‹å®éªŒå¯¹æ¯”:")
            for data in all_data:
                print(f"  {data['name']}:")
                print(f"    æœ€ç»ˆæŸå¤±: {data['final_loss']:.4f}")
                print(f"    æŸå¤±ä¸‹é™: {data['improvement']:.1f}%")
                print(f"    è®­ç»ƒè½®æ•°: {data['epochs']}")

    def demonstrate_reconstruction_difficulty(self):
        """æ¼”ç¤ºä¸åŒæ©ç æ¯”ä¾‹çš„é‡å»ºéš¾åº¦"""
        print(f"\nğŸ¯ æ¼”ç¤ºä¸åŒæ©ç æ¯”ä¾‹çš„é‡å»ºéš¾åº¦...")
        
        if self.dataset is None:
            return
        
        # é€‰æ‹©ä¸€å¼ å›¾ç‰‡ï¼Œæµ‹è¯•ä¸åŒæ©ç æ¯”ä¾‹
        sample = self.dataset[0]
        original_img = sample['image']
        
        if original_img.mode != 'RGB':
            original_img = original_img.convert('RGB')
        
        img_tensor = self.transform(original_img).unsqueeze(0).to(self.device)
        
        # æµ‹è¯•ä¸åŒæ©ç æ¯”ä¾‹
        mask_ratios = [0.1, 0.25, 0.5, 0.75, 0.9]
        
        fig, axes = plt.subplots(3, len(mask_ratios), figsize=(len(mask_ratios)*3, 9))
        
        original_display = torch.clamp(self.inv_normalize(img_tensor[0]).cpu(), 0, 1)
        
        reconstruction_losses = []
        
        for i, mask_ratio in enumerate(mask_ratios):
            # ä½¿ç”¨25%è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
            with torch.no_grad():
                loss, pred, mask = self.model_25(img_tensor, mask_ratio=mask_ratio)
                reconstructed = self.model_25.unpatchify(pred)
                
                # æ©ç å¯è§†åŒ–
                mask_vis = mask.detach().unsqueeze(-1).repeat(1, 1, self.model_25.patch_embed.patch_size[0]**2 * 3)
                mask_vis = self.model_25.unpatchify(mask_vis)
            
            masked_img = original_display * (1 - mask_vis[0].cpu()) + mask_vis[0].cpu() * 0.5
            recon_display = torch.clamp(self.inv_normalize(reconstructed[0]).cpu(), 0, 1)
            
            # æ˜¾ç¤ºåŸå›¾ï¼ˆåªåœ¨ç¬¬ä¸€åˆ—æ˜¾ç¤ºï¼‰
            if i == 0:
                axes[0, i].imshow(original_display.permute(1, 2, 0))
                axes[0, i].set_title('Original')
                axes[0, i].axis('off')
            else:
                axes[0, i].axis('off')
            
            # æ˜¾ç¤ºæ©ç å›¾
            axes[1, i].imshow(masked_img.permute(1, 2, 0))
            axes[1, i].set_title(f'{mask_ratio*100:.0f}% Masked')
            axes[1, i].axis('off')
            
            # æ˜¾ç¤ºé‡å»ºå›¾
            axes[2, i].imshow(recon_display.permute(1, 2, 0))
            axes[2, i].set_title(f'Reconstructed\nLoss: {loss.item():.3f}')
            axes[2, i].axis('off')
            
            reconstruction_losses.append(loss.item())
            print(f"  {mask_ratio*100:.0f}%æ©ç : æŸå¤± {loss.item():.4f}")
        
        plt.tight_layout()
        
        # ä¿å­˜éš¾åº¦æ¼”ç¤º
        difficulty_path = self.output_dir / 'reconstruction_difficulty_demo.png'
        plt.savefig(difficulty_path, dpi=150, bbox_inches='tight')
        print(f"âœ… é‡å»ºéš¾åº¦æ¼”ç¤ºä¿å­˜: {difficulty_path}")
        plt.close()
        
        # åˆ†æéš¾åº¦è¶‹åŠ¿
        print(f"\nğŸ¯ é‡å»ºéš¾åº¦åˆ†æ:")
        print(f"  æ©ç æ¯”ä¾‹è¶Šé«˜ï¼Œé‡å»ºæŸå¤±è¶Šå¤§ï¼ˆä»»åŠ¡è¶Šéš¾ï¼‰")
        for i, (ratio, loss) in enumerate(zip(mask_ratios, reconstruction_losses)):
            difficulty = "ç®€å•" if loss < 1.0 else "ä¸­ç­‰" if loss < 1.2 else "å›°éš¾"
            print(f"  {ratio*100:3.0f}%æ©ç : {loss:.4f} ({difficulty})")

    def create_summary_report(self):
        """åˆ›å»º25%æ©ç å®éªŒæ€»ç»“æŠ¥å‘Š"""
        print(f"\nğŸ“ åˆ›å»ºå®éªŒæ€»ç»“æŠ¥å‘Š...")
        
        report_path = self.output_dir / 'mask25_experiment_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# 25% æ©ç æ¯”ä¾‹ MAE å®éªŒæŠ¥å‘Š\n\n")
            f.write(f"**å®éªŒæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**æ•°æ®é›†**: AnimeDiffusion (500å¼ å›¾ç‰‡)\n\n")
            f.write(f"**è®¾å¤‡**: Apple M4 MPS\n\n")
            
            f.write("## å®éªŒè®¾ç½®\n\n")
            f.write("- æ©ç æ¯”ä¾‹: 25% (vs æ ‡å‡†çš„75%)\n")
            f.write("- è®­ç»ƒè½®æ•°: 10 epochs\n")
            f.write("- æ‰¹æ¬¡å¤§å°: 8\n")
            f.write("- å›¾åƒåˆ†è¾¨ç‡: 1920Ã—1080 â†’ 224Ã—224\n")
            f.write("- ç¼©æ”¾ç­–ç•¥: smart_crop\n\n")
            
            f.write("## ä¸»è¦å‘ç°\n\n")
            f.write("### 1. è®­ç»ƒæ•ˆæœ\n")
            f.write("- æœ€ç»ˆæŸå¤±: **0.8099** (ä¼˜äº75%æ©ç çš„0.9511)\n")
            f.write("- è®­ç»ƒæ—¶é—´: 20åˆ†31ç§’\n")
            f.write("- æ”¶æ•›ç¨³å®š: æŸå¤±å¹³ç¨³ä¸‹é™\n\n")
            
            f.write("### 2. æ©ç æ¯”ä¾‹å½±å“\n")
            f.write("- **25%æ©ç **: ä»»åŠ¡è¾ƒç®€å•ï¼Œæ¨¡å‹å­¦ä¹ æ›´å®¹æ˜“\n")
            f.write("- **75%æ©ç **: ä»»åŠ¡è¾ƒå›°éš¾ï¼Œä½†å­¦ä¹ åˆ°æ›´å¼ºçš„è¡¨å¾\n")
            f.write("- **æƒè¡¡**: ç®€å•ä»»åŠ¡ vs è¡¨å¾èƒ½åŠ›\n\n")
            
            f.write("### 3. é‡å»ºè´¨é‡\n")
            f.write("- 25%æ©ç é‡å»ºè´¨é‡æ›´é«˜\n")
            f.write("- æ›´å¤šå¯è§åŒºåŸŸå¸®åŠ©æ¨¡å‹æ¨æ–­\n")
            f.write("- é€‚åˆå¿«é€ŸéªŒè¯å’Œè°ƒè¯•\n\n")
            
            f.write("## ç”Ÿæˆæ–‡ä»¶\n\n")
            f.write("- `mask25_training_curves.png`: è®­ç»ƒæ›²çº¿\n")
            f.write("- `mask_ratio_comparison.png`: 25% vs 75% å¯¹æ¯”\n")
            f.write("- `reconstruction_difficulty_demo.png`: ä¸åŒæ©ç æ¯”ä¾‹éš¾åº¦æ¼”ç¤º\n")
            f.write("- `comprehensive_mask_comparison.png`: ç»¼åˆå¯¹æ¯”åˆ†æ\n\n")
        
        print(f"âœ… å®éªŒæŠ¥å‘Šä¿å­˜: {report_path}")

    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„25%æ©ç å®éªŒåˆ†æ"""
        print("ğŸ¯ å¼€å§‹25%æ©ç å®éªŒå®Œæ•´åˆ†æ...")
        print("=" * 60)
        
        # 1. åˆ†æè®­ç»ƒæ›²çº¿
        self.analyze_training_curves()
        
        # 2. å¯¹æ¯”ä¸åŒæ©ç æ¯”ä¾‹
        self.compare_mask_ratios_on_same_images()
        
        # 3. æ¼”ç¤ºé‡å»ºéš¾åº¦
        self.demonstrate_reconstruction_difficulty()
        
        # 4. åˆ›å»ºç»¼åˆå¯¹æ¯”
        self.create_comprehensive_comparison()
        
        # 5. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.create_summary_report()
        
        print(f"\nğŸ‰ 25%æ©ç å®éªŒåˆ†æå®Œæˆ!")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        print(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        for file_path in sorted(self.output_dir.glob("*.png")):
            size = file_path.stat().st_size / 1024  # KB
            print(f"  {file_path.name}: {size:.1f} KB")
        
        return self.output_dir

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ 25% æ©ç æ¯”ä¾‹å®éªŒç»“æœå¯è§†åŒ–")
    print("=" * 50)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨å¹¶è¿è¡Œå®Œæ•´åˆ†æ
    visualizer = Mask25Visualizer()
    output_dir = visualizer.run_complete_analysis()
    
    print(f"\nğŸ’¡ å…³é”®å‘ç°:")
    print(f"  âœ… 25%æ©ç è®­ç»ƒæ›´å®¹æ˜“æ”¶æ•›")
    print(f"  âœ… æœ€ç»ˆæŸå¤±æ›´ä½ (0.8099 vs 0.9511)")
    print(f"  âœ… é‡å»ºè´¨é‡æ›´é«˜")
    print(f"  âš ï¸  ä½†å­¦ä¹ åˆ°çš„è¡¨å¾å¯èƒ½ä¸å¦‚75%æ©ç å¼º")
    
    print(f"\nğŸš€ å»ºè®®ä¸‹ä¸€æ­¥:")
    print(f"  1. å°è¯•ä¸­ç­‰æ©ç æ¯”ä¾‹ (50%)")
    print(f"  2. åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¯„ä¼°ä¸åŒæ©ç æ¯”ä¾‹è®­ç»ƒçš„æ¨¡å‹")
    print(f"  3. æ¢ç´¢æœ€ä¼˜çš„æ©ç æ¯”ä¾‹")

if __name__ == "__main__":
    main()


