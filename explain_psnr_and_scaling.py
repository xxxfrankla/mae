#!/usr/bin/env python3
"""
è§£é‡ŠPSNRæ¦‚å¿µå’Œå›¾åƒç¼©æ”¾æ•ˆæœ
å±•ç¤º1920Ã—1080ç¼©æ”¾åˆ°224Ã—224çš„å®é™…æ•ˆæœ
"""

import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from datasets import load_dataset

# è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

def explain_psnr():
    """è¯¦ç»†è§£é‡ŠPSNRæ¦‚å¿µ"""
    
    print("ğŸ“Š PSNR (Peak Signal-to-Noise Ratio) è¯¦è§£")
    print("=" * 60)
    
    print("\nğŸ¯ PSNRæ˜¯ä»€ä¹ˆï¼Ÿ")
    print("PSNRæ˜¯è¡¡é‡å›¾åƒè´¨é‡çš„é‡è¦æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°é‡å»º/å‹ç¼©å›¾åƒä¸åŸå›¾çš„ç›¸ä¼¼åº¦")
    
    print("\nğŸ“ PSNRè®¡ç®—å…¬å¼ï¼š")
    print("PSNR = 20 Ã— log10(MAX_PIXEL_VALUE / âˆšMSE)")
    print("å…¶ä¸­ï¼š")
    print("  â€¢ MAX_PIXEL_VALUE = 1.0 (å½’ä¸€åŒ–åçš„æœ€å¤§åƒç´ å€¼)")
    print("  â€¢ MSE = Mean Squared Error (å‡æ–¹è¯¯å·®)")
    print("  â€¢ MSE = mean((original - reconstructed)Â²)")
    
    print("\nğŸ“ˆ PSNRå€¼çš„å«ä¹‰ï¼š")
    quality_levels = [
        ("ğŸŸ¢ ä¼˜ç§€", "> 30dB", "å‡ ä¹çœ‹ä¸å‡ºå·®å¼‚ï¼Œä¸“ä¸šçº§è´¨é‡"),
        ("ğŸ”µ å¾ˆå¥½", "25-30dB", "è½»å¾®å·®å¼‚ï¼Œé«˜è´¨é‡é‡å»º"),
        ("ğŸŸ¡ è‰¯å¥½", "20-25dB", "å¯æ¥å—çš„è´¨é‡ï¼Œæœ‰æ˜æ˜¾ä½†ä¸ä¸¥é‡çš„å·®å¼‚"),
        ("ğŸŸ  ä¸€èˆ¬", "15-20dB", "è´¨é‡ä¸‹é™æ˜æ˜¾ï¼Œä½†ä»å¯ç”¨"),
        ("ğŸ”´ è¾ƒå·®", "10-15dB", "è´¨é‡å¾ˆå·®ï¼Œæœ‰ä¸¥é‡çš„å¤±çœŸ"),
        ("âš« å¾ˆå·®", "< 10dB", "å‡ ä¹æ— æ³•ä½¿ç”¨ï¼Œä¸¥é‡å¤±çœŸ")
    ]
    
    for level, range_str, description in quality_levels:
        print(f"  {level} {range_str:>8}: {description}")
    
    print(f"\nğŸ’¡ æˆ‘ä»¬çš„å®éªŒç»“æœï¼š")
    print(f"  â€¢ å½“å‰PSNR: 9-12dB â†’ ğŸ”´ è´¨é‡è¾ƒå·®")
    print(f"  â€¢ ç›®æ ‡PSNR: >20dB â†’ ğŸŸ¡ å¯æ¥å—è´¨é‡")
    print(f"  â€¢ ç†æƒ³PSNR: >25dB â†’ ğŸ”µ é«˜è´¨é‡é‡å»º")

def demonstrate_psnr_calculation():
    """æ¼”ç¤ºPSNRè®¡ç®—è¿‡ç¨‹"""
    print(f"\nğŸ§® PSNRè®¡ç®—æ¼”ç¤º...")
    
    # åˆ›å»ºç¤ºä¾‹å›¾åƒ
    original = torch.rand(3, 100, 100)  # åŸå§‹å›¾åƒ
    
    # åˆ›å»ºä¸åŒè´¨é‡çš„"é‡å»º"å›¾åƒ
    reconstructions = {
        'å®Œç¾é‡å»º': original.clone(),
        'é«˜è´¨é‡é‡å»º': original + torch.randn_like(original) * 0.05,
        'ä¸­ç­‰è´¨é‡é‡å»º': original + torch.randn_like(original) * 0.1,
        'ä½è´¨é‡é‡å»º': original + torch.randn_like(original) * 0.2,
        'å¾ˆå·®é‡å»º': torch.rand_like(original)  # éšæœºå™ªå£°
    }
    
    print(f"ğŸ“Š ä¸åŒé‡å»ºè´¨é‡çš„PSNRå€¼ï¼š")
    
    fig, axes = plt.subplots(1, len(reconstructions), figsize=(len(reconstructions)*3, 3))
    
    for i, (name, recon) in enumerate(reconstructions.items()):
        # è®¡ç®—MSE
        mse = torch.mean((original - recon)**2).item()
        
        # è®¡ç®—PSNR
        if mse > 0:
            psnr = 20 * torch.log10(torch.tensor(1.0) / torch.sqrt(torch.tensor(mse))).item()
        else:
            psnr = float('inf')
        
        # æ˜¾ç¤ºå›¾åƒ
        axes[i].imshow(torch.clamp(recon, 0, 1).permute(1, 2, 0))
        axes[i].set_title(f'{name}\nPSNR: {psnr:.1f}dB')
        axes[i].axis('off')
        
        print(f"  {name}: MSE={mse:.6f}, PSNR={psnr:.1f}dB")
    
    plt.tight_layout()
    plt.savefig('psnr_demonstration.png', dpi=150, bbox_inches='tight')
    print("âœ… PSNRæ¼”ç¤ºä¿å­˜: psnr_demonstration.png")
    plt.close()

def show_scaling_effects():
    """å±•ç¤ºå›¾åƒç¼©æ”¾æ•ˆæœ"""
    print(f"\nğŸ–¼ï¸ å±•ç¤º1920Ã—1080ç¼©æ”¾åˆ°224Ã—224çš„æ•ˆæœ...")
    
    try:
        # åŠ è½½AnimeDiffusionæ•°æ®é›†
        ds = load_dataset("Mercity/AnimeDiffusion_Dataset")
        
        # é€‰æ‹©å‡ å¼ ä¸åŒé£æ ¼çš„å›¾ç‰‡
        sample_indices = [0, 100, 500, 1000, 2000]
        
        fig, axes = plt.subplots(len(sample_indices), 4, figsize=(16, len(sample_indices)*3))
        
        scaling_methods = [
            ('åŸå›¾ 1920Ã—1080', None),
            ('ç›´æ¥ç¼©æ”¾ 224Ã—224', transforms.Resize((224, 224))),
            ('æ™ºèƒ½è£å‰ª 224Ã—224', transforms.Compose([
                transforms.Resize(int(224 * 1.15)),
                transforms.CenterCrop(224)
            ])),
            ('ä¿æŒæ¯”ä¾‹ç¼©æ”¾', transforms.Compose([
                transforms.Resize(224),  # ä¿æŒå®½é«˜æ¯”
                transforms.CenterCrop(224)
            ]))
        ]
        
        for i, idx in enumerate(sample_indices):
            try:
                sample = ds['train'][idx]
                original_img = sample['image']
                
                if original_img.mode != 'RGB':
                    original_img = original_img.convert('RGB')
                
                print(f"\nå›¾ç‰‡ {i+1} (ç´¢å¼• {idx}):")
                print(f"  åŸå§‹å°ºå¯¸: {original_img.size}")
                
                for j, (method_name, transform_method) in enumerate(scaling_methods):
                    if transform_method is None:
                        # æ˜¾ç¤ºåŸå›¾çš„ç¼©ç•¥å›¾
                        display_img = original_img.resize((224, 126))  # ä¿æŒ16:9æ¯”ä¾‹ç”¨äºæ˜¾ç¤º
                        axes[i, j].imshow(display_img)
                        
                        # è®¡ç®—ä¿¡æ¯æŸå¤±
                        original_pixels = 1920 * 1080
                        target_pixels = 224 * 224
                        info_loss = (1 - target_pixels / original_pixels) * 100
                        
                        axes[i, j].set_title(f'{method_name}\nä¿¡æ¯ä¿ç•™: {100-info_loss:.1f}%')
                    else:
                        # åº”ç”¨ç¼©æ”¾å˜æ¢
                        scaled_img = transform_method(original_img)
                        axes[i, j].imshow(scaled_img)
                        axes[i, j].set_title(f'{method_name}\n{scaled_img.size}')
                    
                    axes[i, j].axis('off')
                
                # è®¡ç®—ç¼©æ”¾æŸå¤±
                original_area = 1920 * 1080
                target_area = 224 * 224
                scale_factor = target_area / original_area
                print(f"  ç¼©æ”¾æ¯”ä¾‹: {scale_factor:.6f} ({scale_factor*100:.3f}%)")
                print(f"  ä¿¡æ¯æŸå¤±: {(1-scale_factor)*100:.1f}%")
                
            except Exception as e:
                print(f"å¤„ç†å›¾ç‰‡ {idx} æ—¶å‡ºé”™: {e}")
                for j in range(4):
                    axes[i, j].text(0.5, 0.5, f'Error', ha='center', va='center')
                    axes[i, j].axis('off')
        
        plt.tight_layout()
        plt.savefig('image_scaling_effects.png', dpi=150, bbox_inches='tight')
        print("âœ… å›¾åƒç¼©æ”¾æ•ˆæœä¿å­˜: image_scaling_effects.png")
        plt.close()
        
    except Exception as e:
        print(f"ç¼©æ”¾æ•ˆæœæ¼”ç¤ºå¤±è´¥: {e}")

def analyze_information_loss():
    """åˆ†æä¿¡æ¯æŸå¤±"""
    print(f"\nğŸ“‰ åˆ†æç¼©æ”¾é€ æˆçš„ä¿¡æ¯æŸå¤±...")
    
    # è®¡ç®—ä¸åŒç¼©æ”¾çš„ä¿¡æ¯æŸå¤±
    resolutions = [
        ('åŸå§‹', 1920, 1080),
        ('é«˜æ¸…', 1280, 720),
        ('æ ‡æ¸…', 640, 480),
        ('MAEè¾“å…¥', 224, 224),
        ('ç¼©ç•¥å›¾', 112, 112)
    ]
    
    original_pixels = 1920 * 1080
    
    print(f"ğŸ“Š ä¸åŒåˆ†è¾¨ç‡çš„ä¿¡æ¯ä¿ç•™ç‡:")
    print(f"{'åˆ†è¾¨ç‡':<12} {'åƒç´ æ•°':<12} {'ä¿¡æ¯ä¿ç•™':<12} {'æŸå¤±ç¨‹åº¦'}")
    print("-" * 50)
    
    info_retention = []
    labels = []
    
    for name, w, h in resolutions:
        pixels = w * h
        retention = pixels / original_pixels * 100
        loss = 100 - retention
        
        if retention > 50:
            loss_level = "è½»å¾®"
        elif retention > 10:
            loss_level = "ä¸­ç­‰"
        elif retention > 1:
            loss_level = "ä¸¥é‡"
        else:
            loss_level = "æä¸¥é‡"
        
        print(f"{name:<12} {pixels:<12,} {retention:<11.2f}% {loss_level}")
        
        info_retention.append(retention)
        labels.append(f"{name}\n{w}Ã—{h}")
    
    # å¯è§†åŒ–ä¿¡æ¯æŸå¤±
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # ä¿¡æ¯ä¿ç•™ç‡æŸ±çŠ¶å›¾
    bars = ax1.bar(labels, info_retention, color=['green', 'blue', 'orange', 'red', 'darkred'], alpha=0.7)
    ax1.set_ylabel('Information Retention (%)')
    ax1.set_title('Information Retention by Resolution')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, retention in zip(bars, info_retention):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                f'{retention:.1f}%', ha='center', va='bottom')
    
    # åƒç´ æ•°å¯¹æ¯”
    pixel_counts = [w*h for _, w, h in resolutions]
    ax2.bar(labels, pixel_counts, color=['green', 'blue', 'orange', 'red', 'darkred'], alpha=0.7)
    ax2.set_ylabel('Total Pixels')
    ax2.set_title('Pixel Count by Resolution')
    ax2.tick_params(axis='x', rotation=45)
    ax2.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('information_loss_analysis.png', dpi=150, bbox_inches='tight')
    print("âœ… ä¿¡æ¯æŸå¤±åˆ†æä¿å­˜: information_loss_analysis.png")
    plt.close()
    
    print(f"\nğŸ’¡ å…³é”®å‘ç°:")
    print(f"  â€¢ 1920Ã—1080 â†’ 224Ã—224: æŸå¤± {100-info_retention[3]:.1f}% çš„ä¿¡æ¯ï¼")
    print(f"  â€¢ è¿™ç›¸å½“äºä¸¢å¼ƒäº† {100-info_retention[3]:.0f}% çš„åƒç´ ç»†èŠ‚")
    print(f"  â€¢ è¿™å¯èƒ½æ˜¯é‡å»ºè´¨é‡å·®çš„é‡è¦åŸå› ")

def show_actual_scaled_images():
    """å±•ç¤ºå®é™…ç¼©æ”¾åçš„å›¾åƒè´¨é‡"""
    print(f"\nğŸ¨ å±•ç¤ºå®é™…ç¼©æ”¾åçš„å›¾åƒ...")
    
    try:
        ds = load_dataset("Mercity/AnimeDiffusion_Dataset")
        
        # é€‰æ‹©å‡ å¼ ä»£è¡¨æ€§å›¾ç‰‡
        test_indices = [0, 100, 500]
        
        fig, axes = plt.subplots(len(test_indices), 3, figsize=(12, len(test_indices)*4))
        
        for i, idx in enumerate(test_indices):
            sample = ds['train'][idx]
            original_img = sample['image']
            prompt = sample.get('long_prompt', sample.get('short_prompt', ''))[:60] + "..."
            
            if original_img.mode != 'RGB':
                original_img = original_img.convert('RGB')
            
            print(f"\nå›¾ç‰‡ {i+1}:")
            print(f"  åŸå§‹å°ºå¯¸: {original_img.size}")
            print(f"  æè¿°: {prompt}")
            
            # åŸå›¾ (ç¼©æ”¾ç”¨äºæ˜¾ç¤º)
            display_original = original_img.resize((400, 225))  # ä¿æŒ16:9æ¯”ä¾‹
            axes[i, 0].imshow(display_original)
            axes[i, 0].set_title(f'Original HD\n1920Ã—1080\n({prompt[:30]}...)')
            axes[i, 0].axis('off')
            
            # ç›´æ¥ç¼©æ”¾åˆ°224Ã—224
            scaled_direct = original_img.resize((224, 224))
            axes[i, 1].imshow(scaled_direct)
            axes[i, 1].set_title('Direct Resize\n224Ã—224\n(May be distorted)')
            axes[i, 1].axis('off')
            
            # æ™ºèƒ½è£å‰ªåˆ°224Ã—224 (æˆ‘ä»¬å®é™…ä½¿ç”¨çš„æ–¹æ³•)
            smart_crop_transform = transforms.Compose([
                transforms.Resize(int(224 * 1.15)),
                transforms.CenterCrop(224)
            ])
            scaled_smart = smart_crop_transform(original_img)
            axes[i, 2].imshow(scaled_smart)
            axes[i, 2].set_title('Smart Crop\n224Ã—224\n(Our method)')
            axes[i, 2].axis('off')
            
            # è®¡ç®—è´¨é‡æŸå¤±
            original_array = np.array(original_img.resize((224, 224)))
            smart_array = np.array(scaled_smart)
            
            mse = np.mean((original_array.astype(float) - smart_array.astype(float))**2) / (255**2)
            if mse > 0:
                psnr = 20 * np.log10(1.0 / np.sqrt(mse))
                print(f"  ç¼©æ”¾è´¨é‡æŸå¤±: PSNR {psnr:.1f}dB")
            else:
                print(f"  ç¼©æ”¾è´¨é‡æŸå¤±: æ— æŸå¤±")
        
        plt.tight_layout()
        plt.savefig('actual_scaling_comparison.png', dpi=150, bbox_inches='tight')
        print("âœ… å®é™…ç¼©æ”¾å¯¹æ¯”ä¿å­˜: actual_scaling_comparison.png")
        plt.close()
        
    except Exception as e:
        print(f"ç¼©æ”¾æ¼”ç¤ºå¤±è´¥: {e}")

def create_psnr_quality_examples():
    """åˆ›å»ºä¸åŒPSNRè´¨é‡çš„ç¤ºä¾‹"""
    print(f"\nğŸ­ åˆ›å»ºä¸åŒPSNRè´¨é‡çš„ç¤ºä¾‹...")
    
    # åˆ›å»ºä¸€ä¸ªæ¸…æ™°çš„æµ‹è¯•å›¾åƒ
    test_img = torch.zeros(3, 224, 224)
    
    # æ·»åŠ ä¸€äº›å›¾æ¡ˆ
    # æ¸å˜èƒŒæ™¯
    for i in range(224):
        test_img[:, i, :] = i / 224
    
    # æ·»åŠ ä¸€äº›å‡ ä½•å›¾å½¢
    # ç™½è‰²åœ†å½¢
    center = 112
    radius = 40
    y, x = torch.meshgrid(torch.arange(224), torch.arange(224), indexing='ij')
    circle_mask = (x - center)**2 + (y - center)**2 <= radius**2
    test_img[:, circle_mask] = 1.0
    
    # é»‘è‰²çŸ©å½¢
    test_img[:, 50:100, 150:200] = 0.0
    
    # åˆ›å»ºä¸åŒè´¨é‡çš„ç‰ˆæœ¬
    noise_levels = [0.0, 0.05, 0.1, 0.15, 0.2, 0.3]
    quality_names = ['Perfect', 'Excellent', 'Good', 'Fair', 'Poor', 'Very Poor']
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()
    
    for i, (noise_level, quality_name) in enumerate(zip(noise_levels, quality_names)):
        # æ·»åŠ å™ªå£°
        noisy_img = test_img + torch.randn_like(test_img) * noise_level
        noisy_img = torch.clamp(noisy_img, 0, 1)
        
        # è®¡ç®—PSNR
        mse = torch.mean((test_img - noisy_img)**2).item()
        if mse > 0:
            psnr = 20 * torch.log10(torch.tensor(1.0) / torch.sqrt(torch.tensor(mse))).item()
        else:
            psnr = float('inf')
        
        # æ˜¾ç¤º
        axes[i].imshow(noisy_img.permute(1, 2, 0))
        axes[i].set_title(f'{quality_name}\nNoise: {noise_level:.2f}\nPSNR: {psnr:.1f}dB')
        axes[i].axis('off')
        
        print(f"  {quality_name}: å™ªå£°{noise_level:.2f}, PSNR {psnr:.1f}dB")
    
    plt.tight_layout()
    plt.savefig('psnr_quality_examples.png', dpi=150, bbox_inches='tight')
    print("âœ… PSNRè´¨é‡ç¤ºä¾‹ä¿å­˜: psnr_quality_examples.png")
    plt.close()

def analyze_our_results():
    """åˆ†ææˆ‘ä»¬çš„å®éªŒç»“æœ"""
    print(f"\nğŸ“Š åˆ†ææˆ‘ä»¬çš„MAEå®éªŒç»“æœ...")
    
    experiments = [
        ('åˆæˆæ•°æ®é›†', 'å‡ ä½•å›¾æ¡ˆ', '224Ã—224', '1.31', 'çº¦8dB'),
        ('anime-captions', 'åŠ¨æ¼«å›¾ç‰‡', '512Ã—512â†’224Ã—224', '1.07', 'çº¦9dB'),
        ('AnimeDiffusion-75%', 'é«˜è´¨é‡åŠ¨æ¼«', '1920Ã—1080â†’224Ã—224', '0.95', 'çº¦10dB'),
        ('AnimeDiffusion-25%', 'é«˜è´¨é‡åŠ¨æ¼«', '1920Ã—1080â†’224Ã—224', '0.81', 'çº¦11dB'),
        ('æ”¹è¿›ç‰ˆ25%', 'é«˜è´¨é‡åŠ¨æ¼«', '1920Ã—1080â†’224Ã—224', '0.73', 'çº¦12dB')
    ]
    
    print(f"ğŸ¯ æˆ‘ä»¬çš„å®éªŒPSNRåˆ†æ:")
    print(f"{'å®éªŒ':<20} {'æ•°æ®ç±»å‹':<12} {'åˆ†è¾¨ç‡':<20} {'æŸå¤±':<8} {'ä¼°è®¡PSNR'}")
    print("-" * 80)
    
    for exp_name, data_type, resolution, loss, psnr in experiments:
        print(f"{exp_name:<20} {data_type:<12} {resolution:<20} {loss:<8} {psnr}")
    
    print(f"\nğŸ’¡ å…³é”®è§‚å¯Ÿ:")
    print(f"  â€¢ æ‰€æœ‰å®éªŒçš„PSNRéƒ½åœ¨8-12dBèŒƒå›´")
    print(f"  â€¢ è¿™ä¸ªèŒƒå›´å±äº ğŸ”´ è´¨é‡è¾ƒå·® çº§åˆ«")
    print(f"  â€¢ ä¸»è¦åŸå› ï¼š")
    print(f"    1. å·¨å¤§çš„åˆ†è¾¨ç‡æŸå¤± (97.6%ä¿¡æ¯ä¸¢å¤±)")
    print(f"    2. MAEæ¶æ„é™åˆ¶")
    print(f"    3. è®­ç»ƒæ—¶é—´ä¸è¶³")
    
    print(f"\nğŸ¯ è¦è¾¾åˆ°å¯æ¥å—è´¨é‡ (PSNR > 20dB):")
    print(f"  â€¢ éœ€è¦å°†MSEä»å½“å‰çš„~0.1é™åˆ°<0.01")
    print(f"  â€¢ è¿™éœ€è¦é‡å»ºè¯¯å·®å‡å°‘10å€ä»¥ä¸Š")
    print(f"  â€¢ å¯èƒ½éœ€è¦æ ¹æœ¬æ€§çš„æ–¹æ³•æ”¹å˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š PSNRå’Œå›¾åƒç¼©æ”¾è¯¦è§£")
    print("=" * 50)
    
    # 1. è§£é‡ŠPSNRæ¦‚å¿µ
    explain_psnr()
    
    # 2. æ¼”ç¤ºPSNRè®¡ç®—
    demonstrate_psnr_calculation()
    
    # 3. å±•ç¤ºç¼©æ”¾æ•ˆæœ
    show_scaling_effects()
    
    # 4. åˆ›å»ºè´¨é‡ç¤ºä¾‹
    create_psnr_quality_examples()
    
    # 5. åˆ†ææˆ‘ä»¬çš„ç»“æœ
    analyze_our_results()
    
    print(f"\nğŸ‰ æ€»ç»“:")
    print(f"  ğŸ“Š PSNR: å›¾åƒè´¨é‡çš„å®¢è§‚æŒ‡æ ‡ï¼Œ>20dBæ‰ç®—å¯æ¥å—")
    print(f"  ğŸ–¼ï¸  ç¼©æ”¾: 1920Ã—1080â†’224Ã—224æŸå¤±äº†97.6%çš„ä¿¡æ¯")
    print(f"  ğŸ” æˆ‘ä»¬çš„ç»“æœ: 9-12dBï¼Œå±äºè´¨é‡è¾ƒå·®çº§åˆ«")
    print(f"  ğŸ’¡ æ”¹è¿›æ–¹å‘: éœ€è¦å¤§å¹…æå‡é‡å»ºç²¾åº¦")

if __name__ == "__main__":
    main()


