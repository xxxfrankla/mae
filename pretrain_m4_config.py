#!/usr/bin/env python3
"""
Apple M4 24GB MAE é¢„è®­ç»ƒé…ç½®ç”Ÿæˆå™¨
æ ¹æ®ç¡¬ä»¶é™åˆ¶ç”Ÿæˆåˆé€‚çš„è®­ç»ƒå‚æ•°
"""

import os
import argparse

def create_m4_configs():
    """ä¸ºä¸åŒåœºæ™¯åˆ›å»º M4 é€‚é…çš„é…ç½®"""
    
    configs = {
        # å¿«é€Ÿæµ‹è¯•é…ç½® (å‡ åˆ†é’ŸéªŒè¯)
        "quick_test": {
            "batch_size": 4,
            "accum_iter": 16,  # æ¨¡æ‹Ÿ 64 çš„ batch size
            "epochs": 5,
            "model": "mae_vit_base_patch16",
            "blr": 1.5e-4,
            "warmup_epochs": 1,
            "description": "å¿«é€ŸéªŒè¯é…ç½®ï¼Œ5ä¸ªepoch"
        },
        
        # å°è§„æ¨¡å®éªŒé…ç½® (å‡ å°æ—¶)
        "small_experiment": {
            "batch_size": 8,
            "accum_iter": 32,  # æ¨¡æ‹Ÿ 256 çš„ batch size
            "epochs": 50,
            "model": "mae_vit_base_patch16", 
            "blr": 1.5e-4,
            "warmup_epochs": 5,
            "description": "å°è§„æ¨¡å®éªŒï¼Œ50ä¸ªepoch"
        },
        
        # ä¸­ç­‰è§„æ¨¡è®­ç»ƒ (1-2å¤©)
        "medium_training": {
            "batch_size": 8,
            "accum_iter": 64,  # æ¨¡æ‹Ÿ 512 çš„ batch size
            "epochs": 200,
            "model": "mae_vit_base_patch16",
            "blr": 1.5e-4,
            "warmup_epochs": 20,
            "description": "ä¸­ç­‰è§„æ¨¡è®­ç»ƒï¼Œ200ä¸ªepoch"
        },
        
        # é•¿æœŸè®­ç»ƒé…ç½® (å‡ å¤©åˆ°ä¸€å‘¨)
        "long_training": {
            "batch_size": 6,
            "accum_iter": 85,  # æ¨¡æ‹Ÿ ~512 çš„ batch size
            "epochs": 400,
            "model": "mae_vit_base_patch16",
            "blr": 1.5e-4,
            "warmup_epochs": 40,
            "description": "é•¿æœŸè®­ç»ƒï¼Œ400ä¸ªepoch"
        }
    }
    
    return configs

def generate_command(config_name, data_path, output_dir="./output_m4"):
    """ç”Ÿæˆè®­ç»ƒå‘½ä»¤"""
    configs = create_m4_configs()
    
    if config_name not in configs:
        print(f"âŒ é…ç½® '{config_name}' ä¸å­˜åœ¨")
        print(f"å¯ç”¨é…ç½®: {list(configs.keys())}")
        return None
    
    config = configs[config_name]
    
    # è®¡ç®—æœ‰æ•ˆ batch size
    effective_batch_size = config["batch_size"] * config["accum_iter"]
    actual_lr = config["blr"] * effective_batch_size / 256
    
    command = f"""# {config['description']}
# æœ‰æ•ˆ batch size: {effective_batch_size}
# å®é™…å­¦ä¹ ç‡: {actual_lr:.2e}

export KMP_DUPLICATE_LIB_OK=TRUE

python main_pretrain.py \\
    --batch_size {config['batch_size']} \\
    --accum_iter {config['accum_iter']} \\
    --epochs {config['epochs']} \\
    --model {config['model']} \\
    --norm_pix_loss \\
    --mask_ratio 0.75 \\
    --blr {config['blr']} \\
    --weight_decay 0.05 \\
    --warmup_epochs {config['warmup_epochs']} \\
    --data_path {data_path} \\
    --output_dir {output_dir} \\
    --log_dir {output_dir} \\
    --device mps \\
    --num_workers 4 \\
    --pin_mem"""
    
    return command, config

def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ Apple M4 MAE é¢„è®­ç»ƒé…ç½®')
    parser.add_argument('--config', choices=['quick_test', 'small_experiment', 'medium_training', 'long_training'],
                       default='quick_test', help='é€‰æ‹©é…ç½®ç±»å‹')
    parser.add_argument('--data_path', required=True, help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--output_dir', default='./output_m4', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--save_script', action='store_true', help='ä¿å­˜ä¸ºè„šæœ¬æ–‡ä»¶')
    
    args = parser.parse_args()
    
    command, config = generate_command(args.config, args.data_path, args.output_dir)
    
    if command:
        print(f"ğŸ Apple M4 MAE é¢„è®­ç»ƒé…ç½®: {args.config}")
        print("=" * 60)
        print(command)
        
        if args.save_script:
            script_name = f"run_pretrain_{args.config}.sh"
            with open(script_name, 'w') as f:
                f.write("#!/bin/bash\n")
                f.write(command)
            os.chmod(script_name, 0o755)
            print(f"\nâœ… è„šæœ¬å·²ä¿å­˜: {script_name}")
        
        # æ˜¾ç¤ºé…ç½®è¯´æ˜
        print(f"\nğŸ“Š é…ç½®è¯¦æƒ…:")
        print(f"  æ¨¡å‹: {config['model']}")
        print(f"  æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
        print(f"  æ¢¯åº¦ç´¯ç§¯: {config['accum_iter']}")
        print(f"  æœ‰æ•ˆæ‰¹æ¬¡: {config['batch_size'] * config['accum_iter']}")
        print(f"  è®­ç»ƒè½®æ•°: {config['epochs']}")
        print(f"  é¢„çƒ­è½®æ•°: {config['warmup_epochs']}")
        
        # ä¼°ç®—è®­ç»ƒæ—¶é—´
        estimate_time(config)

def estimate_time(config):
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    print(f"\nâ±ï¸  è®­ç»ƒæ—¶é—´ä¼°ç®— (åŸºäº ImageNet-1K):")
    
    # åŸºäºæµ‹è¯•ç»“æœçš„ä¼°ç®—
    # ViT-Base, batch_size=8, ~100ms/batch on M4
    images_per_epoch = 1281167  # ImageNet train set
    batches_per_epoch = images_per_epoch // (config['batch_size'] * config['accum_iter'])
    time_per_batch = 0.1  # 100ms estimated
    
    time_per_epoch = batches_per_epoch * time_per_batch / 60  # minutes
    total_time = time_per_epoch * config['epochs'] / 60  # hours
    
    print(f"  æ¯è½®çº¦: {time_per_epoch:.1f} åˆ†é’Ÿ")
    print(f"  æ€»è®¡çº¦: {total_time:.1f} å°æ—¶ ({total_time/24:.1f} å¤©)")
    
    if total_time > 48:
        print("  âš ï¸  è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä½¿ç”¨ screen æˆ– tmux")

if __name__ == "__main__":
    main()
