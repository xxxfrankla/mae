#!/usr/bin/env python3
"""
å¯»æ‰¾å’Œä¸‹è½½åŒ…å«è§£ç å™¨æƒé‡çš„å®Œæ•´MAEæ¨¡å‹
"""

import os
import sys
import requests
import torch
from urllib.parse import urlparse
import json

def check_facebook_mae_models():
    """æ£€æŸ¥Facebookå®˜æ–¹MAEæ¨¡å‹"""
    print("ğŸ” æ£€æŸ¥Facebookå®˜æ–¹MAEæ¨¡å‹...")
    
    # Facebook MAEå®˜æ–¹æ¨¡å‹é“¾æ¥
    official_models = {
        "mae_pretrain_vit_base": {
            "url": "https://dl.fbaipublicfiles.com/mae/pretrain/mae_pretrain_vit_base.pth",
            "description": "ViT-Baseé¢„è®­ç»ƒæ¨¡å‹ï¼ˆåªæœ‰ç¼–ç å™¨ï¼‰"
        },
        "mae_pretrain_vit_large": {
            "url": "https://dl.fbaipublicfiles.com/mae/pretrain/mae_pretrain_vit_large.pth", 
            "description": "ViT-Largeé¢„è®­ç»ƒæ¨¡å‹ï¼ˆåªæœ‰ç¼–ç å™¨ï¼‰"
        },
        "mae_pretrain_vit_huge": {
            "url": "https://dl.fbaipublicfiles.com/mae/pretrain/mae_pretrain_vit_huge.pth",
            "description": "ViT-Hugeé¢„è®­ç»ƒæ¨¡å‹ï¼ˆåªæœ‰ç¼–ç å™¨ï¼‰"
        },
        "mae_finetuned_vit_base": {
            "url": "https://dl.fbaipublicfiles.com/mae/finetune/mae_finetuned_vit_base.pth",
            "description": "ViT-Baseå¾®è°ƒæ¨¡å‹ï¼ˆç”¨äºåˆ†ç±»ï¼Œæ— è§£ç å™¨ï¼‰"
        },
        "mae_visualize_vit_large": {
            "url": "https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth",
            "description": "ViT-Largeå¯è§†åŒ–æ¨¡å‹ï¼ˆå¯èƒ½åŒ…å«è§£ç å™¨ï¼ï¼‰"
        },
        "mae_visualize_vit_large_ganloss": {
            "url": "https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large_ganloss.pth",
            "description": "ViT-Large+GANæŸå¤±å¯è§†åŒ–æ¨¡å‹ï¼ˆå¯èƒ½åŒ…å«è§£ç å™¨ï¼ï¼‰"
        }
    }
    
    print(f"ğŸ“‹ å‘ç° {len(official_models)} ä¸ªå®˜æ–¹æ¨¡å‹:")
    for name, info in official_models.items():
        print(f"  â€¢ {name}: {info['description']}")
    
    return official_models

def check_model_contents(model_path):
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å†…å®¹"""
    print(f"\nğŸ” æ£€æŸ¥æ¨¡å‹å†…å®¹: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None
    
    try:
        # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint = torch.load(model_path, map_location='cpu')
        
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        # åˆ†æé”®å€¼
        encoder_keys = []
        decoder_keys = []
        other_keys = []
        
        for key in state_dict.keys():
            if key.startswith('decoder') or key == 'mask_token':
                decoder_keys.append(key)
            elif any(key.startswith(prefix) for prefix in ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']):
                encoder_keys.append(key)
            else:
                other_keys.append(key)
        
        print(f"  ğŸ“Š æ¨¡å‹åˆ†æ:")
        print(f"    ç¼–ç å™¨å‚æ•°: {len(encoder_keys)} ä¸ª")
        print(f"    è§£ç å™¨å‚æ•°: {len(decoder_keys)} ä¸ª")
        print(f"    å…¶ä»–å‚æ•°: {len(other_keys)} ä¸ª")
        
        if len(decoder_keys) > 0:
            print(f"  âœ… åŒ…å«è§£ç å™¨æƒé‡!")
            print(f"    è§£ç å™¨å‚æ•°ç¤ºä¾‹: {decoder_keys[:5]}")
            return True
        else:
            print(f"  âŒ ä¸åŒ…å«è§£ç å™¨æƒé‡")
            return False
            
    except Exception as e:
        print(f"  âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return None

def download_model(url, filename):
    """ä¸‹è½½æ¨¡å‹æ–‡ä»¶"""
    print(f"\nğŸ“¥ ä¸‹è½½æ¨¡å‹: {filename}")
    print(f"  URL: {url}")
    
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        with open(filename, 'wb') as f:
            downloaded = 0
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    if total_size > 0:
                        progress = (downloaded / total_size) * 100
                        print(f"\r  è¿›åº¦: {progress:.1f}% ({downloaded/1024/1024:.1f}MB/{total_size/1024/1024:.1f}MB)", end='')
        
        print(f"\n  âœ… ä¸‹è½½å®Œæˆ: {filename}")
        return True
        
    except Exception as e:
        print(f"\n  âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False

def search_huggingface_models():
    """æœç´¢HuggingFaceä¸Šçš„MAEæ¨¡å‹"""
    print("\nğŸ¤— æœç´¢HuggingFaceä¸Šçš„MAEæ¨¡å‹...")
    
    # ä¸€äº›å¯èƒ½åŒ…å«å®Œæ•´MAEçš„HuggingFaceæ¨¡å‹
    hf_models = [
        {
            "name": "facebook/vit-mae-base",
            "description": "Facebookå®˜æ–¹ViT-MAEæ¨¡å‹",
            "url": "https://huggingface.co/facebook/vit-mae-base"
        },
        {
            "name": "facebook/vit-mae-large", 
            "description": "Facebookå®˜æ–¹ViT-MAE Largeæ¨¡å‹",
            "url": "https://huggingface.co/facebook/vit-mae-large"
        },
        {
            "name": "facebook/vit-mae-huge",
            "description": "Facebookå®˜æ–¹ViT-MAE Hugeæ¨¡å‹", 
            "url": "https://huggingface.co/facebook/vit-mae-huge"
        }
    ]
    
    print("ğŸ“‹ HuggingFace MAEæ¨¡å‹:")
    for model in hf_models:
        print(f"  â€¢ {model['name']}: {model['description']}")
        print(f"    URL: {model['url']}")
    
    return hf_models

def download_huggingface_model():
    """ä¸‹è½½HuggingFaceæ¨¡å‹çš„ç¤ºä¾‹ä»£ç """
    print("\nğŸ“ HuggingFaceæ¨¡å‹ä¸‹è½½ç¤ºä¾‹:")
    
    code_example = '''
# å®‰è£…transformersåº“
pip install transformers

# Pythonä»£ç ç¤ºä¾‹
from transformers import ViTMAEModel, ViTMAEConfig

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆåŒ…å«ç¼–ç å™¨å’Œè§£ç å™¨ï¼‰
model = ViTMAEModel.from_pretrained("facebook/vit-mae-base")

# è¿™ä¸ªæ¨¡å‹åŒ…å«å®Œæ•´çš„ç¼–ç å™¨å’Œè§£ç å™¨
print("ç¼–ç å™¨å±‚æ•°:", len(model.encoder.layer))
print("è§£ç å™¨å±‚æ•°:", len(model.decoder.layer))

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé‡å»º
import torch
from PIL import Image
import requests
from transformers import ViTMAEImageProcessor

# åŠ è½½å›¾åƒå¤„ç†å™¨
processor = ViTMAEImageProcessor.from_pretrained("facebook/vit-mae-base")

# åŠ è½½æµ‹è¯•å›¾åƒ
url = "http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)

# é¢„å¤„ç†
inputs = processor(images=image, return_tensors="pt")

# å‰å‘ä¼ æ’­ï¼ˆåŒ…å«é‡å»ºï¼‰
with torch.no_grad():
    outputs = model(**inputs)
    
# è·å–é‡å»ºç»“æœ
reconstructed_pixel_values = outputs.logits
print("é‡å»ºå›¾åƒå½¢çŠ¶:", reconstructed_pixel_values.shape)
'''
    
    print(code_example)
    
    return code_example

def create_download_script():
    """åˆ›å»ºä¸‹è½½è„šæœ¬"""
    print("\nğŸ“ åˆ›å»ºå®Œæ•´æ¨¡å‹ä¸‹è½½è„šæœ¬...")
    
    script_content = '''#!/bin/bash
# ä¸‹è½½åŒ…å«è§£ç å™¨çš„å®Œæ•´MAEæ¨¡å‹

echo "ğŸ”½ ä¸‹è½½å®Œæ•´MAEæ¨¡å‹..."

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p complete_mae_models
cd complete_mae_models

echo "ğŸ“¥ ä¸‹è½½å¯è§†åŒ–æ¨¡å‹ï¼ˆå¯èƒ½åŒ…å«è§£ç å™¨ï¼‰..."

# ä¸‹è½½å¯è§†åŒ–æ¨¡å‹
curl -L -o mae_visualize_vit_large.pth https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth

curl -L -o mae_visualize_vit_large_ganloss.pth https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large_ganloss.pth

echo "âœ… ä¸‹è½½å®Œæˆï¼"
echo "ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: $(pwd)"
ls -lh *.pth

echo ""
echo "ğŸ’¡ ä½¿ç”¨æ–¹æ³•:"
echo "1. æ£€æŸ¥æ¨¡å‹å†…å®¹: python ../check_model_contents.py"
echo "2. å¦‚æœåŒ…å«è§£ç å™¨ï¼Œå¯ä»¥ç›´æ¥ç”¨äºé‡å»º"
echo "3. å¦‚æœä¸åŒ…å«ï¼Œè€ƒè™‘ä½¿ç”¨HuggingFaceçš„transformersåº“"
'''
    
    with open('download_complete_mae.sh', 'w') as f:
        f.write(script_content)
    
    os.chmod('download_complete_mae.sh', 0o755)
    print("âœ… ä¸‹è½½è„šæœ¬åˆ›å»ºå®Œæˆ: download_complete_mae.sh")

def create_model_checker():
    """åˆ›å»ºæ¨¡å‹æ£€æŸ¥è„šæœ¬"""
    print("\nğŸ“ åˆ›å»ºæ¨¡å‹æ£€æŸ¥è„šæœ¬...")
    
    checker_content = '''#!/usr/bin/env python3
"""
æ£€æŸ¥MAEæ¨¡å‹æ˜¯å¦åŒ…å«è§£ç å™¨æƒé‡
"""

import torch
import sys
import os

def check_mae_model(model_path):
    """æ£€æŸ¥MAEæ¨¡å‹å†…å®¹"""
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
        
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        # ç»Ÿè®¡å‚æ•°
        encoder_keys = [k for k in state_dict.keys() if not k.startswith('decoder') and k != 'mask_token']
        decoder_keys = [k for k in state_dict.keys() if k.startswith('decoder') or k == 'mask_token']
        
        print(f"  ç¼–ç å™¨å‚æ•°: {len(encoder_keys)}")
        print(f"  è§£ç å™¨å‚æ•°: {len(decoder_keys)}")
        
        if len(decoder_keys) > 0:
            print(f"  âœ… åŒ…å«è§£ç å™¨æƒé‡!")
            print(f"  è§£ç å™¨å‚æ•°ç¤ºä¾‹:")
            for key in decoder_keys[:10]:
                print(f"    - {key}")
            return True
        else:
            print(f"  âŒ ä¸åŒ…å«è§£ç å™¨æƒé‡")
            return False
            
    except Exception as e:
        print(f"  âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python check_model_contents.py <model_path>")
        print("ç¤ºä¾‹: python check_model_contents.py pretrained_models/mae_pretrain_vit_base.pth")
        sys.exit(1)
    
    model_path = sys.argv[1]
    check_mae_model(model_path)
'''
    
    with open('check_model_contents.py', 'w') as f:
        f.write(checker_content)
    
    print("âœ… æ¨¡å‹æ£€æŸ¥è„šæœ¬åˆ›å»ºå®Œæˆ: check_model_contents.py")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¯»æ‰¾åŒ…å«è§£ç å™¨æƒé‡çš„å®Œæ•´MAEæ¨¡å‹")
    print("=" * 60)
    
    # 1. æ£€æŸ¥Facebookå®˜æ–¹æ¨¡å‹
    official_models = check_facebook_mae_models()
    
    # 2. æ£€æŸ¥ç°æœ‰æ¨¡å‹
    print(f"\nğŸ” æ£€æŸ¥ç°æœ‰æ¨¡å‹...")
    existing_models = [
        "pretrained_models/mae_pretrain_vit_base.pth",
        "pretrained_models/mae_finetuned_vit_base.pth"
    ]
    
    for model_path in existing_models:
        check_model_contents(model_path)
    
    # 3. æœç´¢HuggingFaceæ¨¡å‹
    hf_models = search_huggingface_models()
    
    # 4. æä¾›ä¸‹è½½ç¤ºä¾‹
    download_huggingface_model()
    
    # 5. åˆ›å»ºä¸‹è½½è„šæœ¬
    create_download_script()
    create_model_checker()
    
    print(f"\nğŸ¯ æ¨èæ–¹æ¡ˆ:")
    print("1. å°è¯•ä¸‹è½½å¯è§†åŒ–æ¨¡å‹ï¼ˆå¯èƒ½åŒ…å«è§£ç å™¨ï¼‰:")
    print("   ./download_complete_mae.sh")
    print()
    print("2. ä½¿ç”¨HuggingFace transformersåº“:")
    print("   pip install transformers")
    print("   from transformers import ViTMAEModel")
    print("   model = ViTMAEModel.from_pretrained('facebook/vit-mae-base')")
    print()
    print("3. æ£€æŸ¥æ¨¡å‹å†…å®¹:")
    print("   python check_model_contents.py <model_path>")
    
    print(f"\nğŸ’¡ å…³äºreshapeé”™è¯¯:")
    print("è¿™é€šå¸¸æ˜¯å› ä¸ºé¢„æµ‹è¾“å‡ºçš„å½¢çŠ¶ä¸æœŸæœ›ä¸åŒ¹é…")
    print("å¯èƒ½éœ€è¦è°ƒæ•´unpatchifyå‡½æ•°æˆ–æ£€æŸ¥patch_sizeè®¾ç½®")

if __name__ == "__main__":
    main()
